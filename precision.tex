\subsection{Removing the Perfect-Precision Arithmetic Assumption}\label{sec:remove-perfect}

In this section we remove the prefect-precision arithmetic assumption. Instead, we only assume that it is possible to compute $\prod_{u=a}^b (1-p_{v,u})$ and $\sum_{u=a}^b p_{v,u}$ to $N$-bit precision, as well as drawing a random $N$-bit word, using polylogarithmic resources. Here we will focus on proving that the family of the random graph we generate via our procedures is statistically close to that of the desired distribution. The main technicality of this lemma arises from the fact that, not only the generator is randomized, but the agent interacting with the generator may choose his queries arbitrarily (or adversarially): our proof must handle any sequence of random choices the generator makes, and any sequence of queries the agent may make.

Observe that the distribution of the graphs constructed by our generator is governed entirely by the samples $u$ drawn from $\distr{F}(v,a,b)$ in Algorithm~\ref{alg:fill}. By our assumption, the CDF of any $\distr{F}(v,a,b)$ can be efficiently computed from $\prod_{u=a}^{u'} (1-p_{v,u})$, and thus sampling with $\frac{1}{\poly(n)}$ error in the $L_1$-distance requires a random $N$-bit word and a binary-search in $\bo(\log (b-a+1)) = \bo(\log n)$ iterations. Using this crucial fact, we prove our lemma that removes the perfect-precision arithmetic assumption.

%Note that throughout the proof, we refer to the pair $\distr{F}(v,a,b), \distr{F}'(v,a,b)$ generically 

\begin{restatable}{lemma}{transition}\label{lemma:transition}
If Algorithm~\ref{alg:fill} (the \func{Fill} operation) is repeatedly invoked to construct a graph $G$ by drawing the value $u$ for at most $S$ times in total, each of which comes from some distribution $\distr{F}'(v,a,b)$ that is $\epsilon$-close in $L_1$-distance to the correct distribution $\distr{F}(v,a,b)$ that perfectly generates the desired distribution $\distr{G}$ over all graphs, then the distribution $\distr{G}'$ of the generated graph $G$ is $(\epsilon S)$-close to $\distr{G}$ in the $L_1$-distance.
\end{restatable}
\begin{proof}
\label{proof:transition}
For simplicity, assume that the algorithm generates the graph to completion according to a sequence of up to $n^2$ distinct buckets $\mathcal{B} = \langle B^{(u_1)}_{v_1}, B^{(u_2)}_{v_2}, \ldots \rangle$, where each $B^{(u_i)}_{v_i}$ specifies the \unfilled~bucket in which any query instigates a \func{Fill} function call. Define an \emph{internal state} of our generator as the triplet $s = (k, u, \ADJ)$, representing that the algorithm is currently processing the $k^\textrm{th}$ \func{Fill}, in the iteration (the \textbf{repeat} loop of Algorithm~\ref{alg:fill}) with value $u$, and have generated $\ADJ$ so far. Let $t_{\ADJ}$ denote the \emph{terminal state} after processing all queries and having generated the graph $G_\ADJ$ represented by $\ADJ$. We note that $\ADJ$ is used here in the analysis but not explicitly maintained; further, it reflects the changes in every iteration: as $u$ is updated during each iteration of \func{Fill}, the cells $\ADJ[v][u'] = \PHI$ for $u' < u$ (within that bucket) that has been skipped are also updated to $\ZERO$.

Let $\mathcal{S}$ denote the set of all (internal and terminal) states. For each state $s$, the generator samples $u$ from the corresponding $\distr{F}'(v,a,b)$ where $\|\distr{F}(v,a,b)-\distr{F}'(v,a,b)\|_1 \leq \epsilon = \frac{1}{\poly(n)}$, then moves to a new state according to $u$. In other words, there is an induced pair of collection of distributions over the states: $(\mathcal{T},\mathcal{T}')$ where $\mathcal{T}=\{\distr{T}_s\}_{s\in\mathcal{S}}, \mathcal{T}'=\{\distr{T}'_s\}_{s\in\mathcal{S}}$, such that $\distr{T}_s(s')$ and $\distr{T}'_s(s')$ denote the probability that the algorithm advances from $s$ to $s'$ by using a sample from the correct $\distr{F}(v,a,b)$ and from the approximated $\distr{F}'(v,a,b)$, respectively. Consequently, $\|\distr{T}_s-\distr{T}'_s\|_1 \leq \epsilon$ for every $s\in\mathcal{S}$.

The generator begins with the initial (internal) state $s_0 = (1, 0, \ADJ_\PHI)$ where all cells of $\ADJ_\PHI$ are $\PHI$'s, goes through at most $S=O(n^3)$ other states (as there are up to $n^2$ values of $k$ and $O(n)$ values of $u$), and reach some terminal state $t_\ADJ$, generating the entire graph in the process. Let $\pi = \langle s^\pi_0 = s_0, s^\pi_1, \ldots, s^\pi_{\ell(\pi)} = t_\ADJ \rangle$ for some $\ADJ$ denote a sequence (``path'') of up to $S+1$ states the algorithm proceeds through, where $\ell(\pi)$ denote the number of transitions it undergoes. For simplicity, let $T_{t_\ADJ}(t_\ADJ)=1$, and $T_{t_\ADJ}(s)=0$ for all state $s \neq t_\ADJ$, so that the terminal state can be repeated and we may assume $\ell(\pi) = S$ for every $\pi$. Then, for the correct transition probabilities described as $\mathcal{T}$, each $\pi$ occurs with probability $q(\pi) = \prod_{i=1}^{S} \distr{T}_{s_{i-1}}(s_i)$, and thus $\distr{G}(G_\ADJ) = \sum_{\pi:s^\pi_{S} = t_\ADJ} q(\pi)$.

Let $\mathcal{T}^{\min}=\{\distr{T}^{\min}_s\}_{s\in\mathcal{S}}$ where $\distr{T}^{\min}_s(s') = \min\{\distr{T}_s(s'),\distr{T}'_s(s')\}$, and note that each $\distr{T}^{\min}_s$ is not necessarily a probability distribution. Then, $\sum_{s'} \distr{T}^{\min}_s(s') = 1 - \|\distr{T}_s-\distr{T}'_s\|_1 \geq 1-\epsilon$. Define $q', q^{\min}, \distr{G}'(G_\ADJ),\distr{G}^{\min}(G_\ADJ)$ analogously, and observe that $q^{\min}(\pi) \leq \min\{q(\pi), q'(\pi)\}$ for every $\pi$, so $\distr{G}^{\min}(G_\ADJ) \leq \min\{\distr{G}(G_\ADJ),\distr{G}'(G_\ADJ)\}$ for every $G_\ADJ$ as well. In other words, $q^{\min}(\pi)$ lower bounds the probability that the algorithm, drawing samples from the correct distributions or the approximated distributions, proceeds through states of $\pi$; consequently, $\distr{G}^{\min}(G_\ADJ)$ lower bounds the probability that the algorithm generates the graph $G_\ADJ$.

Next, consider the probability that the algorithm proceeds through the prefix $\pi_i = \langle s^\pi_0, \ldots, s^\pi_{i}\rangle$ of $\pi$. Observe that for $i \geq 1$,
\begin{align*}\sum_{\pi} q^{\min}(\pi_i) &=\sum_{\pi} q^{\min}(\pi_{i-1})\cdot \distr{T}^{\min}_{s^\pi_{i-1}}(s^\pi_{i}) 
= \sum_{s,s'} \sum_{\pi:s^\pi_{i-1} = s,s^\pi_{i} = s'} q^{\min}(\pi_{i-1})\cdot \distr{T}^{\min}_{s}(s') \\
&= \sum_{s'} \distr{T}^{\min}_s(s')\cdot\sum_{s} \sum_{\pi:s^\pi_{i-1} = s} q^{\min}(\pi_{i-1})
\geq (1-\epsilon) \sum_{\pi} q^{\min}(\pi_{i-1}).\end{align*}
Roughly speaking, at least a factor of $1-\epsilon$ of the ``agreement'' between the distributions over states according to $\mathcal{T}$ and $\mathcal{T}'$ is necessarily conserved after a single sampling process. As $\sum_{\pi} q^{\min}(\pi_0)=1$ because the algorithm begins with $s_0 = (1, 0, \ADJ_\PHI)$, by an inductive argument we have $\sum_{\pi} q^{\min}(\pi)=\sum_{\pi} q^{\min}(\pi_S) \geq (1-\epsilon)^S \geq 1-\epsilon S$. Hence, $\sum_{G_\ADJ} \min\{\distr{G}(G_\ADJ),\distr{G}'(G_\ADJ)\} \geq \sum_{G_\ADJ} \distr{G}^{\min}(G_\ADJ) \geq 1-\epsilon S$, implying that $\|\distr{G}-\distr{G}'\|_1 \leq \epsilon S$, as desired. In particular,  by substituting $\epsilon = \frac{1}{\poly(n)}$ and $S = O(n^3)$, we have shown that Algorithm~\ref{alg:fill} only creates a $\frac{1}{\poly(n)}$ error in the $L_1$-distance. 
\end{proof}

We remark that \func{Random-Neighbor} queries also require that the returned edge is drawn from a distribution that is close to a uniform one, but this requirement applies only \emph{per query} rather then over the entire execution of the generator. Hence, the error due to the selection of a random neighbor may be handled separately from the error for generating the random graph; its guarantee follows straightforwardly from a similar analysis.


%\anak{Ronitt says the proof above is known (e.g., from pseudorandomness) and will help find a reference.}
\iffalse
We defer its proof in Section~\ref{proof:transition}, and provide a high-level proof sketch here.
To prove Lemma~\ref{lemma:transition}, we consider an arbitrary sequence of up to $n^2$ queries  $Q = \langle q_i \rangle$, where $q_i \in V$ specifies the vertex in which the query \func{Next-Neighbor} is invoked. We represent a \emph{state} of the generator as triplet $s = (k, u, \ADJ)$, representing that the algorithm is currently processing the $k^\textrm{th}$ \func{Next-Neighbor} query in the iteration with value $u$, and have generated $\ADJ$ so far. Then, each random choice sampled from $\distr{F}$ and $\distr{F}'$ maps each state $s$ to some new state $s'$; in other words, they describe the transition probability that the generator moves to its next state. The distributions of the new states according to each $\distr{F}$ and $\distr{F}'$ only differ by $\epsilon = \frac{1}{\poly(n)}$ in the $L_1$-distance; that is, at least a factor of $1-\epsilon$ of the ''agreement'' between the distributions over states according to these two transitions is necessarily conserved after a single sampling process. 

Observe that a generator can only undergo at most $S = O(n^3)$ states before it generate the entire graph: for the specification of a state $s = (k, u, \ADJ)$, there are up to $n^2$ values of $k$ and $O(n)$ values of $u$. By an inductive argument, the distribution of $\ADJ$ generated by the ''correct'' sequence of distributions $\distr{F}$'s and the ``actual'' sequence of distributions $\distr{F}'$'s still agree on at least a fraction of $(1-\epsilon)^S \geq 1-\epsilon S = 1-\frac{1}{\poly(n)}$ of their probability masses, yielding the desired $L_1$-distance guarantee.
We remark that our proof above is rather robust: it is straightforward to embed more information into the state depending on the application, and the proof will still guarantee the desired correctness as long as $\epsilon S \leq \frac{1}{\poly(n)}$.
\fi

