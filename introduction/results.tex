\subsection{Our results and techniques}

\anak{TODO: Is this subsection presented well? Are we mixing our results with related works too much here? Should we add a table (arxiv version)? Does it overlap too much with the above stuff? Should we highlight multivariate hypergeometric distribution?}

Our work provides local-access generators for the following
aforementioned three families of random graphs, 
where each query is processed using $\poly(\log n)$ 
time, random bits, and additional space, with no initialization overhead. 
Assuming constant computation time for each arithmetic operation with
$O(\log n)$-bit precision, each of our generators constructs a random graph
drawn from a distribution that is $\frac{1}{\poly(n)}$-close
to the desired distribution in the $L_1$-distance.
\footnote{The \emph{$L_1$-distance} between two probability distributions $\distr{p}$ 
and $\distr{q}$ over domain $D$ is defined as $\|\distr{p-q}\|_1 = 
\sum_{x \in D } |p(x)-q(x)|$.
We say that $\distr{p}$ and $\distr{q}$ are $\epsilon$-close if $\|\distr{p-q}\|_1 \leq \epsilon$. 
%Note that the \emph{total variation distance} is related to the $L_1$-distance as $d_{\mathrm{TV}}(\matr{p},\matr{q})=\frac{1}{2}\|\distr{p-q}\|_1$.
}
\anak{I saw \href{https://stat.mit.edu/calendar/optimal-lower-bounds-for-universal-relation-and-for-samplers-and-finding-duplicates-in-streams}{Jelani's 9/29 talk abstract} describing this ``$L_1$-close'' output as: with prob $1-\epsilon$ the generator outputs something close to the desired distribution; with prob $\epsilon$ can do anything, like fail or output something outside the support. That's an alternative to giving an explicit definition, I suppose; also a good sign we're consider a suitable notion.}

The main complication in our setup, as compared to \cite{reut},
arises from the fact that our graph is undirected.
Each next neighbor query, can affect the probabilties
of a large number of other vertices.
For instance, if $u_1$, and $u_2$ are sampled as two consecutive neighbors of $v$,
we have to maintain consistency in all subsequent steps,
by ensuring that none of the vertices in the range $(u_1,u_2)$
return $v$ as a neighbor.

We present both a deterministic, and a randomized strategy to deal with this.
The randomized algorithm, presented in Section~\ref{sec:ER-rand},
uses the result from Lemma~\ref{alg:oblivious-coin-toss}.
The deterministic algorithm is presented in Section~\ref{sec:ER-det}.

\paragraph{Erd\"{o}s-R\'{e}nyi model}
First, we design generators for constructing $G(n,p)$ graphs.
%Our final local-access implementation answers both adjacency matrix and adjacency list queries
%with $poly(\log n)$ overhead. It is worth noting that if we use this to generate the entire graph,
%we obtain an almost optimal \emph{global} generator that takes $\tilde{\Bo}(m)$ time.
%This matches the bound presented in \cite{er_gen}, upto $\Bo(\log n)$ factors.
We first provide a generator supporting \func{next-neighbor} queries using $\poly(\log n)$ resources per query \emph{in the worst case}:  
In particular, note that when the graph is sparse,
maintaining an adjacency matrix is impossible as a \func{next-neighbor} call may ``skip'' as many as $\Theta(n)$ vertices, and updating this matrix would take linear time. 
Our implementation allows access to the graph's adjacency list representation, enumerating all neighbors of each queried vertex in the lexicographical order. 
We remark that, while $\Omega(n+m)$ time is clearly necessary to generate a full random graph, our implementation supports the local-access via \func{next-neighbor} queries, and yet can generate a full graph within $\widetilde{O}(n+m)$ time, which is tight up to polylogarithmic factors.

We avoid making random choices for all edges by sampling for the index of the next neighbor directly using the geometric distribution (used in \cite{er_gen}).
The difficulty of this approach lies in succinctly and efficiently maintaining the state of the generated graph.
Finding the next neighbor of $v$ requires verifying whether each vertex $u$ has already been decided as a neighbor or a non-neighbor of $v$ during a previous \func{next-neighbor}$(u)$ call, or whether $u$ remains a potential neighbor.
Instead, we observe that it is sufficient to simply maintain the last returned neighbor and all known neighbors for each vertex to compute the status of $u$. We then design a data structure (Section~\ref{sec:ER-det}) that counts and samples the next neighbor while restricting to only the potential neighbors of $v$, and prove that given accurate samples from the geometric distribution one may achieve the desired guarantee in the $L_1$-distance. Additionally, we augment our implementation so that \func{vertex-pair} queries are also supported in $\poly(\log n)$ \emph{amortized} time.

We also provide an alternative implementation that does not require any complicated data structure (Section~\ref{sec:ER-rand}).
Instead, it samples for the next neighbor without excluding the known non-neighbors,
then retries the sampling process if it samples a non-neighbor.
While this approach may encounter many failures, especially if many vertices has been designated as non-neighbors of $v$,
we prove that such an event is extremely unlikely to take more than $O(\log n)$ tries.
This guarantee applies for \emph{arbitrary probabilities} and an
\emph{adversarial} series of queries,
even when the adversary knows the random bits used by the algorithm.
Our generator answers every query using $\poly(\log n)$ resources per query with high probability.
\footnote{An event happens \emph{with high probability} if it holds with probability $\ge 1-n^{-c}$ for any constant $c > 0$.}

\paragraph{Stochastic Block model}
We generalize the $G(n,p)$ construction to the Stochastic Block Model under random community assignment.
Our approach is similarly to sample for the next neighbor directly,
although it does not simply follow the geometric distribution,
as the probabilities for the potential edges now depend on the communities of endpoints.
To handle this issue, we observe that it is sufficient to count
the number of vertices of each community in any interested range of contiguous vertex indices.
We then design a data structure extending a construction of \cite{huge},
which maintain these counts for ranges of vertices, and ``sample'' the partition of their counts only on an as-needed basis.
This extension results in an efficient technique  to sample counts from the \emph{multivariate hypergeometric distribution}.
For $r$ communities, this yields an implementation with $r\,\poly(\log n)$ overhead in required resources for each operation.
This upholds all previous polylogarithmic guarantees when $r = \poly(\log n)$.

\paragraph{Small-World model} 
We design generators for the aforementioned case of the Small-World model, supporting each \func{all-neighbors} query, listing all neighbors from closest to furthest away from the queried vertex, using $\poly(\log n)$ resources per query. Providing local access for directed graphs is simpler because the out-neighbors of vertices may be chosen independently at each vertex, so the main challenge is to sample for the next (closest) neighbor, when the probabilities are a function of the Manhattan distance on the lattice. Rather than sampling for a neighbor directly, we sample the next smallest distance with a neighbor, employing the rejection sampling technique that allows efficient sampling through an approximate distribution that have closed-form description, then as a second step, sample for all neighbors for each chosen distance.

\paragraph{CDF Based Sampling}
It is worth noting that our techniques for implementing local-access for the ER and SBM graphs
can easily be extended to other similar models of random graphs.
The only requirement is that the CDF of the probability sequences can be efficiently computed as in Section~\ref{para:CDF}.

