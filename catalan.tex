\section{Implementing Random Catalan Objects}%
\label{sec:catalan_objects}
%Earlier, we were interested in querying the following random object.
%In a random permutation of $n$ white marbles and $n$ black marbles, how many white marbles are present in the first $k$ positions.
%As we have seen before, \cite{huge} gives us a method of sampling from this (hypergeometric) distribution.
%In constructing a implementation for the Stochastic Block model, we generalized this by adding more colors (multivariate hypergeometric distribution).
%We also took this to the extreme where all marbles are distinguishable (i.e. a random permutation),
%and saw that this could also be implemented efficiently.
%Now we focus on a more challenging variant of this question with more complicated conditional dependences among the placement of the marbles.
\todo[inline,color=red!80!green!25]{$S_{left}$ etc are too large to compute, but we can approximate teh ratios.}

In the previous Section~\ref{sec:application_sbm} on the Stochastic Block Model, we considered random sequences of colored marbles.
Next, we focus on an important variant of these sequences as Catalan objects, which impose a global constraint on the types of allowable sequences.
Specifically, consider a sequence of $n$ white and $n$ black marbles,
such that every \emph{prefix} of the sequence has at least as many white marbles as black ones.
Our goal will be to support queries to a uniformly random instance of such an object.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/basic_dyck_path.pdf}
    \caption{Simple Dyck path with $n = 35$ up and down steps.}
    \label{fig:basic_dyck}
\end{figure}
One interpretation of Catalan objects is given by Dyck paths (Figure~\ref{fig:basic_dyck}).
A Dyck path is essentially a $2n$ step \emph{balanced} one-dimensional walk with exactly $n$ up and down steps.
In Figure~\ref{fig:basic_dyck}, each step moves one unit along the positive $x$-axis (time) and one unit up or down the positive $y$-axis (position).
The prefix constraint implies that the $y$-coordinate of any point on the walk is $\ge 0$ i.e. the walk never crosses the $x$-axis.
The number of possible Dyck paths (see Theorem~\ref{thm:number_of_dyck_paths}) is the $n^{th}$ Catalan number $C_n=\frac{1}{n+1}\cdot{2n\choose n}$.
Many important combinatorial objects occur in Catalan families of which these are an example.

We will approach the problem of partially sampling Catalan objects through Dyck paths.
This, in turn, will allow us to implement access other random Catalan objects such as rooted trees, and bracketed expressions.
Specifically, we will want to answer the following queries:
\begin{itemize}
    \item \func{Direction}$(t)$: Returns the value of the $t^{th}$ step in the Dyck path (whether the step is up or down).
    \item \func{Height}$(t)$: Returns the $y$-position of the path after $t$ steps
    (the number of up steps minus the number of down steps among the first $t$ steps).
    Since a $\func{Direction}(t)$ query can be simulated using the queries $\func{Height}(t)$ and $\func{Height}(t-1)$,
    we will not explicitly discuss the \func{Direction} queries in what follows.
    \item \func{First-Return}$(t)$: If the $(t+1)^{th}$ step is upwards i.e. $\func{Height}(t+1) = \func{Height}(t)+1$,
    it returns the smallest index $t'>t$ such that $\func{Height}(t')=\func{Height}(t)$.
    While it may not be clear why this query is important, it will be useful for querying bracketed expressions and random trees.
    (see Section~\ref{sec:bijections_to_other_catalan_objects}).
\end{itemize}



\subsection{Bijections to other Catalan objects}%
The $\func{Height}$ query is natural for Dyck paths, but the $\func{First-Return}$ query is important in exploring other Catalan objects.
For instance, consider a random well bracketed expression; equivalently an uniform distribution over the Dyck language.
One can construct a trivial bijection between Dyck paths and words in this language
by replacing up and down steps with opening and closing brackets respectively (Figure~\ref{fig:dyck_bijection}).
The $\func{Height}$ query corresponds to asking for the nesting depth at a certain position in the word,
and $\func{First-Return}(x)$ returns the position after the matched closing bracket for the step $(x\rightarrow x+1)$.

\label{sec:bijections_to_other_catalan_objects}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/dyck_tree_bijection.pdf}
    \caption{Bijections from Dyck paths to bracketed expressions and ordered rooted trees.
    Note that the color coded \emph{positions} on the path correspond to tree nodes, and the path itself is a DFS traversal of the tree.
    The bijection to bracketed expressions proceeds by directly replacing up and down steps with opening and closing backets respectively
    (we color the brackets with the \emph{higher} endpoint of the corresponding step).
    Green dashed arrows show successive $\func{First-Return}$ queries on the path.
    Using the bijection, this is equivalent to revealing three child sub-trees in order from left to right for the corresponding tree node,
    and also to finding matching brackets in bracketed expressions.
    \func{First-Return} is not defined for the red boxed nodes in either forward or reverse direction,
    since this position corresponds to a leaf node in the tree, or to a terminal nesting level in the bracket expression.}
    \label{fig:dyck_bijection}
\end{figure}
There is also a natural bijection between Dyck paths and ordered rooted trees (Figure~\ref{fig:dyck_bijection}),
by viewing the Dyck path as a transcript of the tree's DFS traversal.
Starting with the root, for each ``up-step'' we move to a new child of the current node, and for each ``down-step'', we backtrack towards the root.
Thus, the $\func{Height}$ query returns the depth of a node.
Also, since the Dyck path is a DFS transcript of the tree, a $\func{First-Return}$ query on the path
can be used to find successive children of a tree node (each return produces the \emph{next child}).
For instance, in Figure~\ref{fig:dyck_bijection}, we can invoke \func{First-Return} thrice
starting at the first \emph{yellow path position} to reveal the corresponding three children of the \emph{yellow tree node}.
%A similar argument shows a bijection to the set of all ordered binary trees.

By definition, \func{First-Return}$(x)$ is meaningful only when the step from $x$ to $x+1$ is upwards,
i.e. when $\func{Height}(x+1) = \func{Height}(x) + 1$.
We can also implement a \func{Reverse-First-Return} query, which is just a standard \func{First-Return} query on the reversed Dyck path
(consider a reversal of the green dashed arrows in Figure~\ref{fig:dyck_bijection}).
The reversal implies that \func{Reverse-First-Return}$(x)$ is only meaningful when $\func{Height}(x-1) = \func{Height}(x) + 1$.
In terms of bijections, \func{Reverse-First-Return} is equivalent to finding a matching opening bracket in bracketed expressions,
and a \func{Previous-Child} query in rooted trees.
We show how to implement this query in Section~\ref{sec:reverse_first_return_queries}.
In the case where the height at $x$ is larger than both the heights at $x-1$ and $x+1$ (boxed nodes in Figure~\ref{fig:dyck_bijection}),
there is no meaningful ``first return'' from the context of the bijections.
Specifically, these nodes correspond to leaf nodes in rooted trees, or to a terminal nesting level in the bracket expression.

Moving forwards, we will focus on Dyck paths for the sake of simplicity.



\subsection{Catalan Trapezoids and Generalized Dyck Paths}
In order to implement local access to random Dyck paths, we will need to analyze more general Catalan objects.
Specifically, we consider a sequence of $U$ up-steps and $D$ down-steps,
such that any prefix of the sequence containing $U'$ up and $D'$ down steps satisfies $U'-D' \ge 1-k$.
This means that we start our Dyck path at a height of $k-1$, and we are never allowed to cross below zero (Figure~\ref{fig:complex_dyck}).
Note that the case $k=1$ corresponds to the standard description of Dyck paths, as mentioned previously (Figure~\ref{fig:basic_dyck}).
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/complex_dyck_path.pdf}
    \caption{Generalized Dyck path with $U = 25$, $D = 22$ and $k = 3$.
             Note that the boundary is $k-1 = 2$ units below the starting height.} \label{fig:complex_dyck}
\end{figure}

We will denote the set of such \emph{generalized Dyck paths} as $\mathbb C_k(U,D)$ and the number of paths as $C_k(U,D) = |\mathbb C_k(U,D)|$,
which is an entry in the \textit{Catalan Trapezoid} of order $k$ \cite{trap}.
We also use $\mathsf C_k(U,D)$ to denote the uniform distribution over $\mathbb C_k(n,m)$.
Now, we state a result from \cite{trap} without proof:
\begin{align}
    \label{eq:catalan_trapezoid}
    C_k(U,D)=
    \begin{cases}
    \binom{U+D}{D} &0\le D<k\\
    \binom{U+D}{D} - \binom{U+D}{D-k} &k\le D\le U+k-1\\
    0 &D>U+k-1
    \end{cases}
\end{align}
For $k = 1$ and $n=m$, these represent the vanilla Catalan numbers i.e. $C_n = C_1(n,n)$ (number of simple Dyck paths).
Our goal is to sample from the distribution $\mathsf C_1(n,n)$.

Consider the situation after a sequence of \func{Height} queries to the Dyck path at various locations $\langle x_1, x_2,\cdots, x_m \rangle$,
such that the corresponding heights were sampled to be $ \langle y_1, y_2,\cdots, y_m \rangle$.
These revealed locations partition the path into disjoint \emph{intervals} $[x_i,x_{i+1}]$,
where the heights of the endpoints of each interval have been determined (as $y_i = \func{Height}(x_i)$).
We notice that these intervals can be generated independently of each other.
Specifically, the path within the interval $[x_i, x_{i+1}]$ will be sampled from $\mathsf C_k(U,D)$,
where $k - 1 = y_i$, $U + D = x_{i+1} - x_i$, and $U-D = y_{i+1} - y_i$.
Moreover, since the heights of the endpoints $y_i$ and $y_{i+1}$ are known, this choice is independent of any samples outside the interval.
Next, in Section~\ref{sec:implementing_height_queries}, we will show how one can determine heights within such an interval,
and in Section~\ref{sec:supporting_first_return_queries} we will move on to the more complicated $\func{First-Return}$ queries.

%We also maintain a threshold $\mathcal T = \Theta(\log^4 n)$.
%If a query lands in an interval that has length less than $\mathcal T$, then we brute force  the entire interval one step at a time.
%Assuming that the probabilities of these events can be approximated efficiently (Lemma~\ref{lem:probability_approximation_oracle},
%this take $\poly(\log n)$ time.



\subsection{Implementing \func{Height} queries}
\label{sec:implementing_height_queries}
We implement $\func{Height}(t)$ by showing how to (efficiently) determine the height of the path in the midpoint of an existing interval $[x_i, x_{i+1}]$
(where the heights of the endpoints are $y_i$ and $y_{i+1}$).
We can then extend this to arbitrary positions by running a binary search on the appropriate interval using the midpoint samples.
If the interval in question has odd length, we sample a single step from an endpoint, and proceed with a shortened even length interval.
Sampling a single step is easy since there are only two outcomes, and we can explicitly compute the probabilities for either outcome,
as in Lemma~\ref{lem:probability_approximation_oracle} (see Section~\ref{sec:computing_probabilities}).
\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth]{images/dyck_height_sampling.pdf}
    \caption{The $2B$-interval is split into two equal parts resulting in two separate Dyck problems.
             The green node (center) is the sampled height of the midpoint parameterized by the value of $d$.
             The path considered in both sub-intervals starts at a yellow node (left and right edges) and ends at the green node.
             From this perspective, the path on the right is reversed with up and down steps being swapped.
             A possible path is shown in gray.}
    \label{fig:dyck_height_sampling}
\end{figure}

Our general recursive step is as follows.
We consider an interval of length $2B$ comprising of $2U$ up-steps and $2D$ down-steps where the sum of any prefix cannot be less than $k-1$
i.e. the path within this interval should be sampled from $\mathsf C_k(2U,2D)$.
In order to make the analysis simpler, we have assumed that the number of up and down steps are both even.
The case of sampling according to $\mathsf C_k(2U+1, 2D+1)$ works similarly with slightly different formulae.
Without loss of generality, we assume that $D\le U$; if this were not the case, we could simply flip the interval,
swap the up and down steps, and modify the prefix constraint to $k'=k+2U-2D$ (Figure~\ref{fig:dyck_height_sampling}).
This ensures that the overall path in the interval is non-decreasing in height, which will simpify our analysis.

We determine the height of the path $B = U+D$ steps into the interval at the midpoint (see Figure~\ref{fig:dyck_height_sampling}).
This is equivalent to finding the number of up or down steps that get assigned to the first half of the interval.
We parameterize the possibilities by $d$ and define $p_d$ to be the probability that exactly $U+d$ up-steps and $D-d$ down steps
get assigned to the first half (with the remaining $U-d$ up steps and $D+d$ down steps being assigned to the second half).
\begin{align}
\label{eq:height_sampling_probability}
p_d = \frac{S_{left}(d)\cdot S_{right}(d)}{S_{total}(d)}
\end{align}
Here, $S_{left}(d)$ denotes the number of possible paths in the first half (using $U+d$ up steps)
and $S_{right}(d)$ denotes the number of possible paths in the second half (using $U-d$ up steps).
Note that all of these paths have to respect the $k$-boundary constraint (cannot dip more than $k-1$ units below the starting height), where $k=y_i+1$.
Moving forwards, we will drop the $d$ when referring to the path counts.
We (conceptually) flip the second half of the interval,
such that the corresponding path begins from the end of the $2B$-interval and terminates at the midpoint (Figure~\ref{fig:dyck_height_sampling}).
This results in a different starting point, and the prefix/boundary constraint will also be different.
Hence, we define $k' = k + 2U - 2D$  to represent the new boundary constraint (since the final height of the $2B$-interval is $k'-1$).
Finally, $S_{total}$ is the total number of possible paths in the $2B$ interval.

We will now use the rejection sampling lemma (Lemma~\ref{lem:rejection_sampling}).
An important point to note is that in order to apply this lemma, we must be able to compute the $p_d$ values at least approximately.
Lemma~\ref{lem:probability_approximation_oracle} in Section~\ref{sec:computing_probabilities} shows how to compute these approximations.
We also use the following lemma to bound the deviation of the path with high probability.
A proof is presented in Section~\ref{sec:dyck_path_boundaries_and_deviations}.
\begin{restatable}{lemma}{DyckPathDeviationBound}
\label{lem:DyckPathDeviationBound}
Consider a contiguous \emph{sub-path} of a simple Dyck path of length $2n$
where the sub-path is of length $2B$ comprising of $U$ up-steps and $D$ down-steps (with $U + D = 2B$).
Then there exists a constant $c$ such that the quantities $|B-U|$, $|B-D|$, and $|U-D|$
are all $<c\sqrt{B\log n}$ with probability at least $1-1/n^2$ for every possible sub-path.
\end{restatable}

This lemma allows us to ignore potential midpoint heights that cause a deviation greater than $c \sqrt{B\log n}$.
A direct implication is that with high probability, the correctly sampled value for $d$ will be $\mathcal O(\sqrt{B\log n})$.
In other words, the height of the midpoint takes on one of only  $\mathcal O(\sqrt{B\log n})$ distinct values with high probability.
This immediately suggests a $\widetilde{\mathcal O}(\sqrt{B})$ time algorithm for determining the midpoint height,
by explicitly computing the probabilities of each of these potential heights, and directly sampling from the resulting distribution.
However, we can go further and obtain a $\mathcal O(poly(\log n))$ time algorithm.


\subsubsection{The Simple Case: Far Boundary}%
\label{sec:the_simple_case}
We first consider the case when the boundary constraint is far away from the starting point, i.e. $k$ is large.
The following lemma (proof in Section~\ref{sec:dyck_path_boundaries_and_deviations}) shows that in this case,
we can safely \emph{ignore} the constraint.  Intuitively, this is because the boundary is so far away,
that we do not hit it with high probability even if we choose a random \emph{unconstrained} path.
\begin{restatable}{lemma}{DyckPathIrrelevantBoundary}
\label{lem:dyck_path_irrelevant_boundary}
Given a Dyck path sampling problem of length $B$ with $U$ up, $D$ down steps, and a boundary at $k$,
there exists a constant $c$ such that if $k > c \sqrt{B\log n}$, then the distribution of paths sampled without a boundary $\mathsf C_{\infty}(U,D)$
is $\mathcal O(1/n^2)$-close in $L_1$ distance to the distribution of Dyck paths $\mathsf C_k(U+D)$.
\end{restatable}
By Lemma~\ref{lem:dyck_path_irrelevant_boundary}, the problem of sampling from $C_k(2U,2D)$
reduces to sampling from the hypergeometric distribution $C_{\infty}(2U,2D)$ when $k>\mathcal{O}(\sqrt{B\log n})$
i.e. the probabilities $p_d$ can be approximated by:
\[
q_d = \frac{{{B}\choose{D-d}}\cdot{{B}\choose{D+d}}}{{{2B}\choose{2D}}}
\]
This problem of sampling from the hypergeometric distribution is implemented using $\mathcal O(poly(\log n))$ resources in \cite{huge}
%in the context of interval summable functions
(see Lemma~\ref{lem:ggn_interval_summable} in Section~\ref{sec:multivariate_hypergeometric_sampling}).
We also used this result earlier in the paper in order to find the community assignments in the Stochastic Block Model
(Section~\ref{sec:application_sbm}).

\subsubsection{The Difficult Case: Intervals Close to Zero}
\label{sec:the_difficult_case}
The difficult case is when $k = \mathcal{O}(\sqrt{B\log n})$,
and the previous approximation due to Lemma~\ref{lem:dyck_path_irrelevant_boundary} no longer works.
In this case, we cannot just ignore the boundary constraint, and instead we have to analyze the true probability distribution given by $p_d$.
We obtain an expression for $p_d$ by substituting the formula for generalized Catalan numbers as follows:
(Equation~\ref{eq:catalan_trapezoid}) into Equation~\ref{eq:height_sampling_probability}.
\begin{align}
    S_{left} = C_k(U+d,D-d)
    &&S_{right} = C_{k'}(U-d,D+d)
    &&S_{total} = C_k(2U,2D)
\end{align}
Since the right interval is flipped in our analysis, this changes the prefix/boundary constraint,
and hence, the expression for $S_{right}$ uses $k' = k+2U-2D$.
This also implies that $k' = \Bo(\sqrt{B\log n})$ (using Lemma~\ref{lem:DyckPathDeviationBound}).
We can now use Equation~\ref{eq:height_sampling_probability} to evaluate the probabilties $p_d = S_{left}\cdot S_{right}/S_{total}$.
Recall that $S_{left}$ and $S_{right}$ are the number of possible paths in the left and right half of the interval,
when exactly $U+d$ up steps are assigned to the first half, and $S_{total}$ is the total number of possible paths in the interval.

We will invoke the rejection sampling technique (Lemma~\ref{lem:rejection_sampling}), by constructing a different distribution $q_d$
that approximates $p_d$ up to logarithmic factors over the vast majority of its support
(we ignore all $|d|>\Theta(\sqrt{B\log n})$ since the associated probability mass is negligible by Lemma~\ref{lem:DyckPathDeviationBound}).
In order to perform rejection sampling, we also need good approximations of $p_d$,
which is acheved by Lemma~\ref{lem:probability_approximation_oracle} in Section~\ref{sec:computing_probabilities}.
Next, we define an appropriate $q_d$ that approximates $p_d$ and also has an \emph{efficiently computable} $CDF$.
Surprisingly, as in Section~\ref{sec:the_simple_case}, we will be able to use the hypergeometric distribution for $q_d$,
\[
q_d \equiv \frac{{B\choose D-d}\cdot{B\choose D+d}}{{2B\choose 2D}} = \frac{{B\choose D-d}\cdot{B\choose U-d}}{{2B\choose 2D}}
\]
However, the argument for why this $q_d$ is a good approximation to $p_d$ is far less straightforward.

First, we consider the case where $k\cdot k'\le 2U+1$.
In this case, we use loose bounds for $S_{left} < \binom{B}{D-d}$ and $S_{right} < \binom{B}{U-d}$.
These are true because $\binom{B}{D-d}$ and $\binom{B}{U-d}$ are the total number of \emph{unconstrained} paths
in the left and right half respectively, and adding the boundary constraint can only reduce the number of paths.
We also prove the following lemma in Section~\ref{sec:appendix_implementing_height_queries} to bound the value of $S_{total}$.
\begin{restatable}{lemma}{DTotalFarBoundary}
\label{lem:DTotalFarBoundary}
When $kk' > 2U + 1$, $S_{total} > \frac 12\cdot \binom{2B}{2D}$.
\end{restatable}

Combining the three bounds, we conclude that $p_d < \frac 12 q_d$.
Intuitively, in this case the Dyck boundary is far away, and therefore the number of possible paths
is only a constant factor away from the number of unconstrained paths (see Section~\ref{sec:the_simple_case}).
The case where the boundaries are closer (i.e. $k\cdot k' \le 2U+1$) is trickier,
since the individual counts need not be close to the corresponding binomial counts.
However, in this case we can still ensure that the sampling probability is within poly-logarithmic factors of the binomial sampling probability.
We use the following lemmas to bound $S_{left}$ and $S_{right}$ (proofs in Section~\ref{sec:appendix_implementing_height_queries}).
\begin{restatable}{lemma}{DLeftBound}
\label{lem:DLeftBound}
$S_{left} \le c_1 \frac{ k\cdot\sqrt{\log n}}{\sqrt{B}}\cdot{{B}\choose{D-d}}$ for some constant $c_1$.
\end{restatable}
\begin{restatable}{lemma}{DRightBound}
\label{lem:DRightBound}
$S_{right} \le c_2 \frac{k'\cdot \sqrt{log n}}{\sqrt{B}}\cdot{{B}\choose{U-d}}$ for some constant $c_2$.
\end{restatable}

Finally, we obtain a diferent bound on $S_{total}$ for the \emph{near boundary} case.
\begin{restatable}{lemma}{DTotalNearBoundary}
\label{lem:DTotalNearBoundary}
When $kk' \le 2U + 1$, $S_{total} \ge c_3 \frac{k\cdot k'}{B}\cdot{{2B}\choose{2D}}$ for some constant $c_3$.
\end{restatable}

Multiplying these inequalities together allows us to bound $p_d = S_{left}\cdot S_{right}/S_{total} \le \Theta(q_d\log n)$,
implying $p_d/q_d \le \Theta(\log n)$.
Consequently, we can leverage Lemma~\ref{lem:rejection_sampling} to obtain a sample from $\{ p_d\}$
using $\mathcal O(\log^{\mathcal O(1)}n)$ samples from $\{ q_d\}$,
thus determining the height of the Dyck path at the midpoint of the interval.

\begin{theorem}
\label{thm:dyck_midpoint_sampling}
Given an interval $[x_i,x_{i+1}]$ (and the associated endpoint heights $y_i, y_{i+1}$) in a Dyck path of length $2n$,
with the guarantee that no position between $x_i$ and $x_{i+1}$ has been sampled yet,
there is an algorithm that returns the height of the path at the midpoint of $x_i$ and $x_{i+1}$ (or next to the midpoint if $x_{i+1}-x_i$ is odd).
Moreover, this algorithm only uses $\mathcal O(poly(\log n))$ resources.
\end{theorem}
\begin{proof}
If $x_{i+1}-x_i$ is even, we can set $B = (x_{i+1}-x_i)/2$.
Otherwise, we first sample a single step from $x_i$ to $x_i+1$, and then set $B = (x_{i+1}-x_i-1)/2$.
Since there are only two possibilities for a single step, we can explicitly approximate the probabilities, and then sample accordingly.
This allows us to apply the rejection sampling from Lemma~\ref{lem:rejection_sampling}
using $\{ q_d\}$ to obtain samples from $\{ p_d\}$ as defined above.
%Now, if $B > \Theta(\log^2 n)$ we can simply use the rejection sampling procedure described above
%to obtain a $\mathcal O(poly(\log n))$ algorithm.
%Otherwise, we sample each step induividually.
%Since there are only $2B = \Theta(\log^2 n)$ steps, the sampling is still efficient.
\end{proof}

\begin{theorem}
\label{thm:dyck_height_sampling}
There is an algorithm that provides sample access to a Dyck path of length $2n$,
by answering queries of the form \func{Height}$(x)$ with the correctly sampled height of the Dyck path at position $x$
using only $\mathcal O(poly(\log n))$ resources per query.
\end{theorem}
\begin{proof}
The algorithm maintains a successor-predecessor data structure (e.g. Van Emde Boas tree) to store all positions $x$ that have already been determined.
Each newly determined position is added to this structure.
Given a query \func{Height}$(x)$, the algorithm first finds the successor and predecessor (say $a$ and $b$) of $x$ among the already queried positions.
This provides us the guarantee required to apply Theorem~\ref{thm:dyck_midpoint_sampling},
which allows us to query the height at the midpoint of $a$ and $b$.
We then binary search by updating either the successor or predecessor of $x$ and repeat until we determine the height of position $x$.
\end{proof}




\subsection{Supporting ``First Return'' Queries}%
\label{sec:supporting_first_return_queries}
In this section, we discuss more complex queries to a Dyck path.
Specifically, we implement $\func{First-Return}(x)$ to allow the user to query the next time the path returns to \func{Height}$(x)$.
The utility of this kind of query is illustrated through bijections to other random Catalan objects
in Section~\ref{sec:bijections_to_other_catalan_objects}.
An important detail here is that if the first step from $x$ to $x+1$ is an down-step, there is no well defined \func{First-Return}.
%In case of trees, this would correspond to a leaf which has no children.

%We will use the following asymptotic formula for \emph{close-to-central} binomial coefficients
%which will allow us the approximate the probabilities in Section~\ref{sec:estimating_the_cdf}.
%\begin{restatable}{lemma}{CentralBinomialCoefficients}
%\label{lem:CentralBinomialCoefficients}
%(From \cite{asymptopia}) If $k = \frac{n \pm c\sqrt n}{2}$ where $c = o(n^{1/6})$,
%we can approximate $\binom{n}{k}$ up to constant factors by the expression $\frac{2^n}{\sqrt n}\cdot \mathlarger e^{-c^2/2}$.
%\end{restatable}

%Recall that we maintain a threshold $\mathcal T = \Theta(\log^4 n)$ such that
%By setting $\mathcal T = \Theta(\log^4 n)$, we see that for intervals with length $B > \mathcal T$,
%the maximum deviations are bounded by $\mathcal O(\sqrt{B\log n}) = \mathcal O(\log^{2.5}n)$ with high probability.
%This means that if we write the deviation as $c\sqrt B$, we see that $c = \mathcal O(\sqrt{\log n})$ which is $o(B^{1/6})$,
%thus satisfying the condition of Lemma~\ref{lem:CentralBinomialCoefficients}.


\subsubsection{Maintaining a Boundary Invariant}
\label{sec:maintaining_a_boundary_invariant}
Notice that after performing a set of $\func{Height}$ queries $\langle x_1, x_2,\cdots, x_m \rangle$ to the Dyck path,
many different positions are revealed (possibly in adverserial locations).
This partitions the path into at most $m+1$ disjoint and independent \emph{intervals} with known boundary conditions.
The first step towards finding the $\func{First-Return}$ from position $t$ would be to locate the \emph{interval} where the first return occurs.
Even if we had an efficient technique to filter intervals, we would want to avoid considering all $\Theta(m)$ intervals to find the correct one.
In addition, the fact that a specific interval \emph{does not} contain the first return implies dependencies for all subsequent samples.

We resolve these difficulties by maintaining a new invariant.
Consider all positions whose heights have have already been determined, either directly as a result of user given $\func{Height}$ queries,
or indirectly due to recursive $\func{Height}$ calls; $\langle x_1, x_2,\cdots, x_m \rangle$ in increasing order i.e. $x_i<x_{i+1}$.
Let the corresponding heights be $ \langle y_1, y_2,\cdots, y_m \rangle$ i.e. $\func{Height}(x_i) = y_i$.
\begin{invariant}
\label{inv:boundary_invariant}
For any interval $[x_i,x_{i+1}]$ where the heights  of the endpoints have been determined to be $y_i$ and $y_{i+1}$,
and every other height in the interval has yet to determined,
the section of the Dyck path between positions $x_i$ and $x_{i+1}$ is constrained to lie above $min(y_i, y_{i+1})$.
\end{invariant}
\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth]{images/dyck_boundary_invariant.pdf}
    \caption{The set of intervals formed by a set of height samples.
        Each interval also has its own boundary constraint (red).
        Invariant~\ref{inv:boundary_invariant} implies that each boundary must coincide with one of the interval endpoints.
        Note that the only interval which violates the invariant is the third last one (shown in yellow box).}
    \label{fig:dyck_boundary_invariant}
\end{figure}

How can one maintain such an invariant?
After determining the height of a particular position $x_i$ as $y_i$ (with $x_{i-1} < x_i < x_{i+1}$),
the invariant is potentially broken on either side of $x_i$.
We re-establish the invariant by determining the height of an additional point on either side
(see Section~\ref{sec:maintaining_height_queries_under_invariant} for details).
Specifically, we use the following \emph{two step strategy} to find the additional point for some violating interval $[x_i, x_{i+1}]$
(example violation in Figure~\ref{fig:dyck_boundary_invariant}):
\begin{enumerate}
    \item Sample the lowest height $h$ achieved by the walk between $x_i$ and $x_{i+1}$ according to
    the uniform distribution over all possible paths that respect the current boundary constraint
    (see Section~\ref{sec:sampling_the_lowest_achievable_height}).
    \item Find an intermediate position $x$ such that $x_i < x < x_{i+1}$ and $\func{Height}(x) = h$
    (see Section~\ref{sec:sampling_first_position_touching_mandatory_boundary}).
\end{enumerate}
The newly determined position $x$ produces two sub-intervals $[x_i, x]$ and $[x, x_{i+1}]$.
Since $h = \func{Height}(x)$ has been determined to be the minimum height in the overall range $[x_i, x_{i+1}]$,
the invariant is preserved in the new intervals (see Figure~\ref{fig:dyck_invariant_preserve}).
Lemma~\ref{lem:first_return_interval} in Section~\ref{sec:finding_the_correct_interval}
shows how this invariant can help us efficiently search for the interval containing the first return.
\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth]{images/dyck_invariant_preserve.pdf}
    \caption{An interval $[x_i, x_{i+1}]$ that violates the invariant is ``fixed'' by first sampling the lowest height $h$ achieved within the interval,
    and then generating a position $x\in [x_i, x_{i+1}]$ such that $Height(x) = h$.}
    \label{fig:dyck_invariant_preserve}
\end{figure}


\subsubsection{Sampling the Lowest Achievable Height: Mandatory Boundary}\todo{"Sample" used a lot. explanation could be better.}
\label{sec:sampling_the_lowest_achievable_height}
First, we need to sample the lowest height $h$ of the walk between $x_i$ and $x_{i+1}$ (with corresponding heights $y_i$ and $y_{i+1}$).
We will refer to $h$ as the \emph{``mandatory boundary''} in this interval;
i.e. no height in the interval may be lower than the boundary, but at least one point \emph{must} touch the boundary (have height $h$).
We assume that $y_i\le y_{i+1}$ without loss of generality; if this is not the case, swap $x_i$ and $x_{i+1}$ and consider the reversed path.
Say this interval defines a generalized Dyck problem with $U$ up steps and $D$ down steps and a boundary that is $k-1$ units below $y_i$.

\begin{wrapfigure}[16]{r}{0.496\textwidth}
\vspace{-3.0em}
\begin{framed}
    \renewcommand\figurename{Algorithm}
    \caption{Finding the Mandatory boundary}
    \label{alg:mandatory_boundary}
    \begin{algorithmic}[1]
        \Function{Mandatory-Boundary}{$U, D, k$}
            \State {$k_{low}\gets k$}
            \State {$k_{up}\gets 0$}
            \While {$k_{low} < k_{up} - 1$}
                \vspace{.3em}
                \State {$k_{mid}\gets \floor{\frac{(k_{low} + k_{up})}{2}}$}
                \vspace{.3em}
                \State {$P_{total}\gets C_{k_{low}}(U,D) - C_{k_{up}}(U,D)$}
                \vspace{.3em}
                \State {$P_{k_{low}}^{k_{mid}}\gets C_{k_{low}}(U,D) - C_{k_{mid}}(U,D)$}
                \vspace{.3em}
                \State {\textbf{with probability} $P_{k_{low}}^{k_{mid}}/P_{total}$}
                    \State {\hspace{\algorithmicindent}$k_{up}\gets k_{mid}$}
                \State {\textbf{else}}
                    \State {\hspace{\algorithmicindent}$k_{low}\gets k_{mid}$}
            \EndWhile
            \State \Return $k_{low}$
        \EndFunction
    \end{algorithmic}
\end{framed}
\end{wrapfigure}
Given any two boundaries $k_{lower}$ and $k_{upper}$ on this interval (with $k_{lower} < k_{upper} \le y_i$),
we can count the number of possible generalized Dyck paths that violate the $k_{upper}$ boundary but \emph{not} the $k_{lower}$ boundary as:
\[
P_{k_{lower}}^{k_{upper}} = C_{k_{lower}}(U,D) - C_{k_{upper}}(U,D)
\]
We define the current lower and upper boundaries as $k_{low} = k, k_{up} = 0$, and set $k_{mid} = (k_{low} + k_{up})/2$.
Since we can compute the quantities $P_{k_{mid}}^{k_{up}}$, $P_{k_{low}}^{k_{mid}}$, and $P_{total} = P_{k_{low}}^{k_{up}}$,
we can sample a single bit to decide if the \emph{``lower boundary''} should move up or if the \emph{``upper boundary''} should move down.
We then repeat this binary search until we find $k' = k_{low} = k_{up}-1$ and $k'$ becomes the \emph{``mandatory boundary''}
(i.e. the walk reaches the height exactly $k'-1$ units below $y_i$ but no lower.



\subsubsection{Sampling First Position that Touches the \emph{``Mandatory Boundary''}}\todo{Sample?}
\label{sec:sampling_first_position_touching_mandatory_boundary}

Now that we have a ``\emph{mandatory boundary}'' $k$, we just need to sample a position $x$ with height $h = x_i-k+1$.
In fact, we will do something stronger by sampling the \emph{first} time the walk touches the boundary after $x_i$.
As before, we assume that this interval contains $U$ up steps and $D$ down steps.
\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth]{images/dyck_first_approach_sampling.pdf}
    \caption{Zooming into the error in Figure~\ref{fig:dyck_boundary_invariant}.
        We sample a position $x$ (yellow) on the boundary (red),
        such that the section of the path to the left of $x$ never approaches the red boundary (it respects the orange boundary).}
    \label{fig:dyck_mandatory_boundary_sampling}
\end{figure}

We will parameterize the position $x$ the number of up-steps $d$ between $x_i$ and $x$ (See Figure~\ref{fig:dyck_mandatory_boundary_sampling}).
implying that $x = x_{i} + 2d + k - 1$.
Given a specific $d$, we want to compute the number of valid paths that result in
$d$ up-steps before the first approach to the boundary.
Note that unlike Section~\ref{sec:implementing_height_queries}, $d$ is used here to parameterize the (horizontal) $x$-position of the desired point.
We will calculate the probability $p_d$ associated with a particular position
by counting the total number of paths to the left and right of the first approach and multiplying them together.

As in Section~\ref{sec:the_difficult_case}, we define
$S_{left}$ to be the number of paths in the sub-interval before the first approach (left side of Figure~\ref{fig:dyck_mandatory_boundary_sampling}),
$S_{right}$ to be the number of paths following the first approach,
and $S_{total}$ to be the total number of paths that touch the ``mandatory boundary'' at $k$
(note that these quantities are functions of $U,D,k$ and $d$, but we drop the parameters for the sake of clarity):
{\small
\begin{align*}
    S_{left} = C_{k}(d, d+k-2)
    &&S_{right} = C_1(U-d, D-d-k+1)
    &&S_{total} = C_k(U,D) - C_{k-1}(U,D)
\end{align*}}
Our goal is to sample $d$ from the distribution $\{ p_d\}$ where $p_d = S_{left}\cdot S_{right}/S_{total}$.
The application of Lemma~\ref{lem:rejection_sampling} requires us to approximate $\{p_d\}$
with a ``well behaved'' $\{q_d\}$ (one whose CDF can be efficiently estimated).
Since we only require a asymptotic (up to $\poly(\log n)$ factors) approximation to $\{p_d\}$,
it suffices to estimate the number of paths asymptotically as well.
Using Equation~\ref{eq:catalan_trapezoid}, we obtain approximations for $S_{left}$ and $S_{right}$
(Lemma~\ref{lem:ReturnDLeftBound} and Lemma~\ref{lem:ReturnDRightBound} with proofs in Section~\ref{sec:omitted_supporting_first_return_queries}).
Our general strategy will be to integrate continuous versions of these approximations in order to obtain a CDF of some approximating distribution.
\begin{restatable}{lemma}{ReturnDLeftBound}
\label{lem:ReturnDLeftBound}
If $d > \log^4 n$, then $S_{left}(d)
= \Theta\left( \frac{2^{2d+k}}{\sqrt{d}}\mathlarger e^{-r_{left}(d)}\cdot \frac{k-1}{d+k-1}\right)$
where $r_{left}(d) = \frac{(k-2)^2}{2(2d+k-2)}$.
Furthermore, $r_{left}(d)=\mathcal O(\log^2 n)$.
\end{restatable}

\begin{restatable}{lemma}{ReturnDRightBound}
\label{lem:ReturnDRightBound}
If $U+D-2d-k > \log^4 n$, then $S_{right}(d)
= \Theta\left( \frac{2^{U+D-2d-k}}{\sqrt{U+d-2d-k}}\mathlarger e^{-r_{right}(d)}\cdot \frac{U-D+k}{U-d+1}\right)$
where $r_{right}(d) = \frac{(U-D-k-1)^2}{4(U+D-2d-k+1)}$.
Furthermore, $r_{right}(d)=\mathcal O(\log^2 n)$.
\end{restatable}

Unfortunately, these continuous approximation functions obtained do not admit closed form integrals.
The main culprit is the exponential term in both expressions.
We tackle this issue by noticing that the values of the exponents are bounded by $\mathcal O(\log^2 n)$ over the majority of the range of $d$.
Within this range of $d$ values, the approximating functions may be further simplified by taking a piecewise linear approximation,
where each of the pieces corresponds to a fixed value of the \emph{floor of the corresponding exponent}.
This technique is elaborated in Section~\ref{sec:estimating_the_cdf}.

We now consider the \emph{``problematic''} values of $d$ that are outside the range of the two preceding lemmas.
These values are the ones where $d < \log^4 n$ or $2d > U+D-k-\log^4 n$.
Since $d$ is the number of up steps in the left sub-interval, $d \ge 0$.
Further, since the length of the right sub-interval nust be non-negative (see Figure~\ref{fig:dyck_mandatory_boundary_sampling}),
we get $U+D-2d-k+1 \ge 0$.
Thus, we define the \emph{``problematic''} set:
\begin{align}
\label{eq:SetDefinition}
    \mathcal R = \left\{ d\ \mathlarger|\ 0\le d < \log^4 n \textrm{\textbf{\ or\ }} -1 < 2d-U-D+k < \log^4 n \right\}
\end{align}
Clearly, we can bound the size of this set as $|\mathcal R| = \mathcal O(\log^4 n)$.
An immediate consequence of Lemma~\ref{lem:ReturnDLeftBound} and Lemma~\ref{lem:ReturnDRightBound} is the following.

\begin{restatable}{corollary}{ReturnProbabilityBoundNotNormalized}
\label{cor:ReturnProbabilityBoundNotNormalized}
When $d\not \in \mathcal R$,
$S_{left}(d)\cdot S_{right}(d)
= \Theta\left( \frac{2^{U+D}}{\sqrt{d(U+D-2d-k)}}\cdot \mathlarger e^{-r(d)} \cdot \frac{k-1}{d+k-1}\cdot\frac{U-D+k}{U-d+1}\right)$
where $r(d)=\mathcal O(\log^2 n)$.
\end{restatable}



\subsubsection{Estimating the CDF}
\label{sec:estimating_the_cdf}
We use these observations to construct a suitable $\{q_d\}$ that can be used to invoke the rejection sampling lemma (Lemma~\ref{lem:rejection_sampling}).
We will achieve this by constructing a piecewise continuous function $\hat q$,
such that $\hat q(\delta)$ approximates $p_{\floor\delta}$, and then use the integral of $\hat q$ to define the discrete distribution $\{q_d\}$.
As stated in the previous section, we can leverage the fact that when $d \not \in \mathcal R$,
the floor of the exponent $\floor{r(d)}$ only takes $\mathcal O(\log^2 n)$ distinct values
(consequence of Corollary~\ref{cor:ReturnProbabilityBoundNotNormalized}).
Since the ``problematic'' set $\mathcal R$ only has $\mathcal O(\log^4 n)$ values,
we can also deal with these remaining values by simply creating $|\mathcal R|$ additional continuous pieces in the function $\hat q$.
We begin by rewriting $p_d = \Theta\left(\mathcal K \cdot f(d)\cdot e^{-r(d)}\right)$ where:
{\small
    \begin{align}
    \label{eq:dyck_integrable_function}
        \mathcal K = \frac{2^{U+D}}{S_{total}} = \frac{2^{U+D}}{C_k(U,D)-C_{k-1}(U,D)}\ \ \ \
        &&f(d) = \frac{(k-1)(U-D+k)}{\sqrt{d(U+D-2d-k)}(d+k-1)(U-d+1)}
    \end{align}}
Notice that $\mathcal K$ is a constant and $f(d)$ is a function whose integral has a closed form.
Using the fact that $r(d) = \mathcal O(\log^2 n)$ (Corollary~\ref{cor:ReturnProbabilityBoundNotNormalized}),
and $|\mathcal R| = \mathcal O(\log^4 n)$, we obtain the following lemma:

\begin{lemma}
\label{lem:ReturnProbabilityPiecewiseContinuous}
Given the piecewise continuous function
\begin{align*}
    \hat q(\delta) &=
    \begin{cases}
        p_{\floor\delta} &\mbox{if } \floor\delta \in \mathcal R \\ 
        \mathcal K\cdot f(\delta)\cdot exp\left(-\lfloor{r({\scriptstyle\floor\delta})}\rfloor\right)
        & \mbox{if } \floor\delta \not\in \mathcal R
    \end{cases}
    && \mathlarger \implies
    && p_d = \Theta\left( \int\limits_d^{d+1} \hat q(\delta)\right)
\end{align*}
Furthermore, $\hat q(\delta)$ has $\mathcal O(\log^4 n)$ continuous pieces.
%Note that this integral has a closed form for a fixed value of $\floor{r(d)}$.
\end{lemma}
\begin{proof}
For $d \in \mathcal R$, the integral trivially evaluates to exactly $p_d$.
For $d\not\in \mathcal R$, it suffices to show that $p_d = \Theta\left( \hat q(\delta)\right)$ for all $\delta\in [d,d+1)$.
We already know that $p_d = \Theta\left( \mathcal K\cdot f(d)\cdot e^{-r(d)}\right)$.
Moreover, for any $\delta\in [d,d+1)$, the exponential term $e^{-\floor{r(\floor\delta)}}$ in $\hat q(\delta)$
is within a factor of $e$ of the original $e^{-r(\floor\delta)}$ term.

For all $\mathcal O(\log^4 n)$ values $d\in \mathcal R$, $\hat q(\delta)$ is constant on the interval $[d,d+1]$.
Since $r(d) = \mathcal O(\log^2 n)$ by Corollary~\ref{cor:ReturnProbabilityBoundNotNormalized},
the exponential term $e^{-\floor{r(\floor\delta)}}$ in $\hat q(\delta)$ taken on at most $\mathcal O(\log^2 n)$ values.
Thus, $\hat q$ is continuous for a range of $\delta$ correspoding to a fixed value of $\floor{r(\floor\delta)}$,
and so, we conclude that $\hat q$ is piecewise continuous with $\mathcal O(\log^2 n)$ pieces.
\end{proof}

Now, we have everything in place to define the distribution $\{ q_d\}$ that we will be sampling from.
Specifically, we will define $q_d$ and it's CDF $Q_d$ as follows ($\mathcal N$ is the normalizing factor):
{\small
    \begin{align}
        q_d = \left(\int\limits_d^{d+1} \hat q(\delta)\right)\cdot \frac{1}{\mathcal N}
        && Q_d = \left(\int\limits_0^{d+1} \hat q(\delta)\right)\cdot \frac{1}{\mathcal N}
        && \textrm{where }\ \mathcal N = \int\limits_0^{d_{max}+1} \hat q(\delta)
    \end{align}}
%Here the normalizing factor $\mathcal N$ is $\int_0^{d_{max}+1} \hat q(\delta)$.
To show that these can be computed efficiently, it suffices to show that any integral of $\hat q(\delta)$ can be efficiently evaluated.
This follows from the fact that $\hat q$ is piecewise continuous with $\mathcal O(\log^4)$ pieces (Lemma~\ref{lem:ReturnProbabilityPiecewiseContinuous}),
each of which has a closed form integral (since $f(d)$ defined in Equation~\ref{eq:dyck_integrable_function} has an integral).

%However, we also need to be able to compute the constant $\mathcal K = 2^{U+D} = 2^{U+D}S_{total}$.
%The issue is that this value could be too large to compute.
%We mitigate this by fixing a threshold $\mathcal T = \Theta(\log^4 n)$, and ensuring that $U+D > \mathcal T$.
%In the case that $U+D \le \mathcal T$, we directly compute the $p_d$ values, and sample from the explicit distribution.
%Otherwise, we obtain the following lemma:}
%\begin{lemma}
%\label{lem:ReturnProbabilityConstant}
%If $U+D > \Theta(\log^4 n)$, the quantity $\mathcal K = 2^{U+D} = 2^{U+D}S_{total}$ is bounded
%and can be computed efficiently.
%\end{lemma}
%\begin{proof}
%First, notice that $S_{total} = C_k(U,D) - C_{k-1}(U,D)$ is the number of paths with $U$ up steps and $D$ down steps with a boundary at $k$
%First, we compute a $\left( 1\pm 1/n^2\right)$ multiplicative approximation to $\log_2 S_{total}$,
%by using the strategy in Lemma~\ref{lem:probability_approximation_oracle} (Section~\ref{sec:computing_probabilities}).
%Now, we claim that 
%\end{proof}

\begin{lemma}
\label{lem:ReturnProbabilityPiecewiseContinuousIntegral}
Given the function $\hat q_d$ defined in Lemma~\ref{lem:ReturnProbabilityPiecewiseContinuous},
it is possible to approximate the integral $\int_{d_1}^{d_2+1} \hat q(\delta)$ to a multiplicative factor of $\left( 1\pm \frac{1}{n^2} \right)$,
in $\poly(\log n)$ time for any valid $d_1, d_2\in \mathbb Z$ (the bounds must be such that $d_i \ge 0$ and $U+D-2d_i-k+1 \ge 0$).
\end{lemma}
\begin{proof}
We will compute the integral by splitting it up into $\mathcal O(\log^4 n)$ continuous pieces and then approximating the integral over each piece.
The pieces corresponding to values of $d\in \mathcal R$ can be explicitly computed as $\int_d^{d+1} \hat q(\delta) = p_d$
(recall that we can compute $p_d$ using Lemma~\ref{lem:probability_approximation_oracle} from Section~\ref{sec:computing_probabilities}).

The more interesting pieces are over the range of $\delta$ where $\floor\delta\not\in \mathcal R$.
Such a piece is given by a continuous range of values $[\delta_{min}, \delta_{max}]\subseteq [d_1, d_2+1]$,
such that for any $\delta\in [\delta_{min}, \delta_{max}]$, the value of $\floor{r(\floor{\delta})}$ is a constant $E$.
We begin the calculation of $\hat q(\delta) = \mathcal K\cdot f(\delta)\cdot exp(-E)$,
by first computing a $\left( 1\pm 1/n^3\right)$ multiplicative approximation to $\ln \mathcal K = (U + D)\ln 2 - \ln S_{total}$,
using the strategy in Lemma~\ref{lem:probability_approximation_oracle} (Section~\ref{sec:computing_probabilities}).
Since $f(\delta)$ has a closed form integral (Equation~\ref{eq:dyck_integrable_function}),
we can also compute $F = \int_{\delta_{min}}^{\delta_{max}} f(\delta)$.
Using the fact that the exponent is constant over the range $[\delta_{min},\delta_{max}]$, we can write the logarithm of the integral as:
\[
\ln\left(\ \int\limits_{d_{min}}^{d_{max}} \hat q(\delta)\right) = \ln \left( \mathcal K\cdot e^{-E}\cdot F\cdot\right)
= (U + D)\cdot \ln 2 - \ln S_{total} + \ln F - E
\]
If this value is smaller than $-3\ln n$, we can safely ignore it since it contrbuted less than $1/n^3$ to the probability mass.
On the flipside, the logarithm is guaranteed to be bounded by $\mathcal O(1)$.
This upper bound is a result of the fact that $\int \hat q(\delta) = \mathcal O(\sum p_d) = \mathcal O(1)$,
where both the sum and the integral are taken over the entire \emph{valid} range of $d$.
This means that we can exponentiate to obtain the true value of the piecewise integral up to a multiplicative approximation of $(1\pm 1/n^3)$.
Adding the integrals of all the $\mathcal O(\log^4 n)$ pieces together produces the final desired value of the integral.
\end{proof}


Now, we are finally ready to use Lemma~\ref{lem:rejection_sampling} to sample $d$ from the distribution $\{p_d\}$,
using the efficient sampling procedure for $\{q_d\}$.
The only other requirement is the ability to approximate the $p_d$ values, which follows from Lemma~\ref{lem:probability_approximation_oracle}.
\begin{theorem}
\label{thm:first_return_in_interval}
Given a sub-interval $[x_{i},x_{i+1}]$ of a random Dyck path of length $2n$,
such that the only determined heights in the interval are $y_i=\func{Height}(x_i)$ and $y_{i+1}=\func{Height}(x_{i+1})$,
and a mandatory boundary constraint at $k$,
there exists an algorithm that generates a point $x$ within the interval such that $\func{Height}(x) = y_i-k+1$,
using $\poly(\log n)$ time, random bits, and additional space.
\end{theorem}



\subsubsection{Finding the Correct Interval: $\func{First-Return}$ Query}
\label{sec:finding_the_correct_interval}
As before, consider all positions that have been queried already $ \langle x_1, x_2,\cdots, x_m \rangle$ (in increasing order)
along with their corresponding heights $ \langle y_1, y_2,\cdots, y_m \rangle$.
We wish to find the first return to height $y_i$ after $x_i$ (where $y_i = \func{Height}(x_i)$).
Our strategy begins by using Invariant~\ref{inv:boundary_invariant} to find the interval $\mathcal I = [x_k, x_{k+1}]$
containing $\func{First-Return}(x_i)$.
\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth]{images/dyck_finding_correct_interval.pdf}
    \caption{There are only two possible intervals (yellow boxes) that could contain $\func{First-Return}(x_i)$;
    either the interval adjacent to $x_i$, or the interval $[x_{f-1}, x_f]$, where $f$ is the smallest index such that $y_f < x_i$.
    }
    \label{fig:dyck_finding_correct_interval}
\end{figure}
\begin{restatable}{lemma}{FirstReturnInterval}
\label{lem:first_return_interval}
Assuming that Invariant~\ref{inv:boundary_invariant} holds, the interval $(x_{j-1},x_{j}]$ containing $\func{First-Return}(x_i)$
is obtained by setting $j$ to be either the smallest index $f>i$ such that $y_f\le y_i$ or setting $j-1=i$.
\end{restatable}
\begin{proof}
We assume the contrary i.e. there exists some $k\not=f$ and $k\not=i+1$ such that the correct interval is $(x_{k-1},x_k]$.
Since $y_f<y_i$, the position of first return to $y_i$ happens in the range $(x_i,x_f]$.
So, the only possibility is $i+1 < k \le f-1$.
By the definition of $y_f$, we know that both $y_k$ and $y_{k-1}$ are strictly larger than $y_i$.
Invariant~\ref{inv:boundary_invariant} implies that the boundary for this interval $(y_{k-1},y_k]$ is at $\min(y_{k-1},y_k) > y_i$.
So, it is not possible for the first return to be in this interval.
\end{proof}

The good news is that there are only two intervals that we need to worry about, one of which is just the adjacent one $[x_i, x_{i+1}]$.
The problem of finding the other interval that may contain the first return boils down to finding the smallest index $f>i$ such that $y_f\le y_i$.
To this end, we define $M_{[a,b]}$ as the minimum determined height in the range of positions $[a,b]$.
%(lowest $y$-value) of any sampled boundary in the range of positions $[a,b]$ along the Dyck path.

One solution is to maintain a range tree $\mathbf R$ \cite{comp_geo} over the range $[2n]$.
Assuming that $2n = 2^l$, we can view $\mathbf R$ as a complete binary tree with depth $r$.
Every non-leaf node is denoted by $\mathbf R_{[a,b]}$, and corresponds to a range $[a,b]\subseteq[2n]$ that is the union of the ranges of its children.
Each $\mathbf R_{[a,b]}$ stores the value $M_{[a,b]}$ which is is the minimum determined height
in the range of positions $[a,b]$, or $\infty$ if none of the heights have been revealed.
%the height of the last boundary update that affected the entire range $[a,b]$.
The leaf nodes are denoted as $\{\mathbf R_i\}_{i\in[2n]}$, and correspond to the singleton range corresponding to position $i\in [2n]$.
%and by definition, this is the min of the values stored at the children of $\mathbf R_{[a,b]}$.
Note that a node at depth $l'$ will correspond to a range of size $2^{l-l'}$, with the root being associated with the entire range $[2n]$.

We say that the range $[a,b]$ is \emph{canonical} if it corresponds to a range of some $\mathbf{R}_{[a,b]}$ in $\mathbf R$.
By the property of range trees, any arbitrary range can be decomposed into a disjoint union of $O(\log n)$ canonical ranges.
We implement $\mathbf{R}$ to support the following operations:
\begin{itemize}
    \item \func{Update}$(x,y)$: Update the height of the position $x$ to $y$.\\
    This update affects all ranges $[a_i,b_i]$ containing $x$.
    So, for each $[a_i,b_i]$ we set $M_{[a_i,b_i]} = \min\left( M_{[a_i,b_i]}, y\right)$.
    \item \func{Query}$(a,b)$: Return the minimum boundary height in the range $[a,b]$.\\
    We decompose $[a,b]$ into $\mathcal O(\log n)$ \emph{canonical} ranges $ \langle r_1, r_2,\cdots\rangle$,
    %For each $r_i$, we compute $M_{r_i}$ as the minimum over all $R_r$ such that the \emph{canonical} range $r$ contains $r_i$.
    %Equivalently, we set $M_{r_i}$ to be the minimum of all values on the path from $\mathbf R_{r_i}$ to the root of $\mathbf R$,
    %which takes $\mathcal O(\log n)$ time.
    %Note that the values stores in the sub-tree rooted at $\mathbf R_{r_i}$ do not affect $M_{r_i}$,
    %since the coreesponding boundary updates did not affect the \emph{entire} range $r_i$ (these updates only affected canonical sub-ranges of $r_i$).
    and return the minimum of all the $M_{r_i}$ values as $M_{[a,b]}$ (since $[a,b]$ is the union of all $r_i$).
\end{itemize}

Now, we can binary search for $f$ by guessing a value $f'$ and checking if $\func{Query}(x_i,x_{f'}) \le y_i$.
Overall, this requires $\mathcal O(\log n)$ calls to $\func{Query}$, each of which makes $\mathcal O(\log n)$ probes to the range tree.
To avoid an initialization overhead, we only create the node $\mathbf{R}_{[a,b]}$ during the first $\func{Update}$ affecting a position $x\in[a,b]$.
Since a call to $\func{Update}$ can create at most $\mathcal O(\log n)$ new nodes in $\mathbf R$,
the additional space required for each $\func{Height}$ or $\func{First-Return}$ query is still bounded.

\begin{theorem}
\label{thm:dyck_first_return_sampling}
There is an algorithm using $\mathcal O(\log^{\mathcal O(1)} n)$ resources per query that provides access to a random Dyck path of length $2n$,
by answering queries of the form \func{First-Return}$(x_i)$ with the correctly sampled smallest position $x'>x_i$,
where the Dyck path first returns to $\func{Height}(x_i)$.
\end{theorem}
\begin{proof}
In order to make the presentation simpler, we ensure that the next determined position after $x_i$ is $x_i+1$ (in other words $x_{i+1} = x_i + 1$).
This can be done by invoking $\func{Height}(x_i+1)$, if needed.
If $\func{Height}(x_i+1) = y_{i+1} < y_i$, we can terminate because $\func{First-Return}(x_i)$ is not defined.
Otherwise, we notice that in this setting, the first return cannot lie in the adjacent interval $[x_i,x_{i+1}] = [x_i, x_i+1]$.

Hence, we proceed to finding the smallest value $f$ such that $y_f \le y_i$, by using the range tree data structure described above.
Since $\func{Height}(x_{f-1}) > y_i \le \func{Height}(x_f)$ by definition,
the interval $(x_{f-1},x_f]$ must contain at least one position at height $y_i$.
We determine the height at the midpoint of this interval,
and then fix the potential violation of Invariant~\ref{inv:boundary_invariant} by finding another point along with its height.
This essentially breaks up the interval $[x_{f-1},x_f]$ into $\mathcal O(1)$ sub-intervals, each at most half the size of the original.
Based on the newly revealed heights, we again find the (newly created) sub-interval containing the first return in $\mathcal O(1)$ time.
We repeat up to $\mathcal O(\log n)$ times, reducing the size of the intervals in consideration, until the position of the first return is revealed.
\end{proof}

\subsubsection{Maintaining \func{Height} Queries under Invariant~\ref{inv:boundary_invariant}}
\label{sec:maintaining_height_queries_under_invariant}
Finally, we show that the boundary constraints introduced in order to maintain Invariant~\ref{inv:boundary_invariant}
do not interfere with the implementation of \func{Height} queries.
As before, we consider the currently revealed heights $ \langle y_1, y_2,\cdots, y_m \rangle$,
along with the corresponding positions $ \langle x_1, x_2,\cdots, x_m \rangle$ (in increasing order).
Say that we are now presented with a a query $\func{Height}(x)$, where $x_i < x < x_{i+1}$.
As in Section~\ref{sec:implementing_height_queries}, we swap $x_i$ and $x_{i+1}$ if necessary in order to ensure that $y_i < y_{i+1}$.
Due to Invariant~\ref{inv:boundary_invariant}, we know that the lowest achievable height in the interval $[x_i, x_{i+1}]$ is $y_i$,
i.e. the boundary constraint for the left half becomes $k = 1$ instead of $k = y_i + 1$, since the constrained boundary is at height $y_i$.
Similarly, the boundary constraint for the right half becomes $k' = 2U - 2D + 1$.

The algorithm for determining the height at the midpoint $x_{mid}$ of $[x_i,x_{i+1}]$
can proceed as described in Section~\ref{sec:implementing_height_queries}.
Of course, in this scenario, the boundary is never far away, and therefore we should always use the strategy in Section~\ref{sec:the_difficult_case}.
The second step is to re-establish Invariant~\ref{inv:boundary_invariant} in the newly created sub-interval $[x_{mid},x_{i+1}]$\footnote{
Note that the invariant is not broken for the $[x_i,x_{mid}]$ sub-interval since $y_i+1$ was the original boundary constraint.
In general, the invariant will be automatically preserved for one of the sub-intervals; the side corresponding to $\min(y_i,y_{i+1})$.},
using the two step strategy from Section~\ref{sec:maintaining_a_boundary_invariant}.
This involves determining the height of one additional point $x'\in [x_{mid},x_{i+1}]$.
Finally, we can continue with the height sampling algorithm from Theorem~\ref{thm:dyck_height_sampling},
by recursively halving one of the newly created intervals (the one containing $x$).
Figure~\ref{fig:dyck_invariant_height_queries} illustrates the aforementioned three steps.
\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth]{images/dyck_invariant_height_queries.pdf}
    \caption{Performing \func{Height} queries while maintaining Invariant~\ref{inv:boundary_invariant}.
    The first step is to determine the height at the midpoint $x_{mid}$ of an existing interval $[x_i,x_{i+1}]$ that contains $x$.
    Next, we re-establish Invariant~\ref{inv:boundary_invariant} by sampling an additional point $x'$ within the violating interval
    Finally, we recurse on the appropriate sub-interval (yellow box).
    }
    \label{fig:dyck_invariant_height_queries}
\end{figure}

Hence, we can combine results from Theorem~\ref{thm:dyck_height_sampling} and Theorem~\ref{thm:dyck_first_return_sampling} to obtain the following:
\CatalanGrand*


\subsubsection{\func{Reverse-First-Return} Queries}
\label{sec:reverse_first_return_queries}
For the sake of completeness, we also sketch how to implement a \func{Reverse-First-Return} query,
which is just a standard \func{First-Return} query on the reversed Dyck path.
This type of query was motivated in Section~\ref{sec:bijections_to_other_catalan_objects},
and can be applied to positions $x$ where $\func{Height}(x-1) = \func{Height}(x)+1$.

Note that Invariant~\ref{inv:boundary_invariant} remains unchanged as it is symmetric to reversal of the Dyck path.
Specifically, the invariant on a particular interval does not change if we swap the endpoints of the interval.
First, we can find the correct interval containing $\func{Reverse-First-Return}(x)$, by using an analog of Lemma~\ref{lem:first_return_interval}.
\begin{restatable}{lemma}{ReverseFirstReturnInterval}
\label{lem:reverse_first_return_interval}
Assuming Invariant~\ref{inv:boundary_invariant}, the interval $[x_{j},x_{j+1})$ containing $\func{Reverse-First-Return}(x_i)$
is obtained by setting $j$ to be either the largest index $f<i$ such that $y_f\le y_i$ or setting $j+1=i$.
\end{restatable}
Since the range tree defined in Section~\ref{sec:finding_the_correct_interval} allows us to query the minimum in arbitrary contiguous ranges,
we can also use it to find the appropriate $f$ for Lemma~\ref{lem:reverse_first_return_interval} through binary search.
Once we have found an interval that is known to contain the \func{Reverse-First-Return},
we can follow the strategy from the proof of Theorem~\ref{thm:dyck_first_return_sampling};
recursively sub-dividing the relevant interval and finding the newly created sub-interval that contains the return,
until we converge on the correct return position.
