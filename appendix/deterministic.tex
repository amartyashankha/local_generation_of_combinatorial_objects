\section{\func{Next-Neighbor} Implementation with Deterministic Performance Guarantee}
\label{sec:ER-det}
In this section, we construct data structures that allow us to sample for the next neighbor directly by considering only the cells $\ADJ[v][u]=\PHI$ in the Erd\"{o}s-R\'{e}nyi model and the Stochastic Block model. This provides $\poly(\log n)$ \emph{worst-case} performance guarantee for implementations supporting only the \func{Next-Neighbor} queries. We may again extend this data structure to support \func{Vertex-Pair} queries, however, at the cost of providing $\poly(\log n)$ \emph{amortized} performance guarantee instead.

In what follows, we first focus on the $G(n,p)$ model, starting with \func{Next-Neighbor} queries (Section~\ref{sec:det-er}) then extend to \func{Vertex-Pair} queries (Section~\ref{sec:det-er-pair}. We then explain how this result may be generalized to support the Stochastic Block model with random community assignment in Section~\ref{sec:det-sbm}.

\subsection{Data structure for next-neighbor queries in the Erd\"{o}s-R\'{e}nyi model}\label{sec:det-er}

\begin{wrapfigure}[14]{r}{0.42\textwidth}
\vspace{-1.5em}
\begin{framed}
    \renewcommand\figurename{Algorithm}
    \caption{Alternate implementation}
    \label{alg:exact-coin-toss}
    \begin{algorithmic}
        \Procedure{Next-Neighbor}{$v$}
            \State{$w \gets \min K_v$, or $n+1$ if $K_v = \emptyset$}
            \State{$t \gets$ \func{count}$(v)$}
            \State{\textbf{sample} $F\sim\mathsf{ExactF}(p,t)$}
            \If{$F \leq t$}
                \State{$u \gets$ \func{pick}$(v,F)$}
                \State{$K_u \gets K_u \cup \{v\}$}
            \Else
                \State{$u \gets w$}
                \If{$u \neq n+1$}
                    \State{$K_v \gets K_v \setminus \{u\}$}
                \EndIf
            \EndIf
            \State{\func{update}$(v,u)$}
            \State{$\LAST[v] \gets u$}
            \State \Return $u$
        \EndProcedure
    \end{algorithmic}
\end{framed}
\end{wrapfigure}

Recall that \func{Next-Neighbor}$(v)$ is given by $\min\{u > \LAST[v]: X_{vu} = 1\}$ (or $n+1$ if no satisfying $u$ exists). To aid in computing this quantity, we define:
\begin{align*}
K_v &= \{u \in (\LAST[v], n]: \ADJ[v][u]=1\},\\
w_v &= \min K_v \textrm{, or $n+1$ if $K_v = \emptyset$,} \\
T_v &= \{u \in (\LAST[v], w_v): \ADJ[v][u] = \PHI\}.
\end{align*}
The ordered set $K_v$ is only defined for ease of presentation: it is equivalent to $(\LAST[v],n] \cap P_v$, recording the known neighbors of $v$ after $\LAST[v]$ (i.e., those that have not been returned as an answer by any \func{Next-Neighbor}$(v)$ query yet). The quantity $w_v$ remains unchanged but is simply restated in terms of $K_v$. $T_v$ specifies the list of candidates $u$ for \func{Next-Neighbor}$(v)$ with $\ADJ[v][u] = \PHI$; in particular, all candidates $u$'s, such that the corresponding RVs $X_{vu} = \ZERO$ are decided, are explicitly excluded from $T_v$.

Unlike the approach of Algorithm~\ref{alg:oblivious-coin-toss} that simulates coin-flips even for decided $X_{vu}$'s, here we only flip undecided coins for the indices in $T_v$: we have $|T_v|$ Bernoulli trials to simulate. Let $F$ be the random variable denoting the first index of a successful trial out of $|T_v|$ coin-flips, or $|T_v|+1$ if all fail; denote the distribution of $F$ by $\mathsf{ExactF}(p,|T|)$. The CDF of $F$ is given by $\mathbb P[F = f] = 1-(1-p)^f$ for $f \leq |T_v|$ (i.e., there is some success trial in the first $f$ trials), and $\mathbb P[F = |T_v|+1] = 1$. Thus, we must design a data structure that can compute $w_v$, compute $|T_v|$, find the $F^\textrm{th}$ minimum value in $T_v$, and update $\ADJ[v][u]$ for the $F$ lowest values $u \in T_v$ accordingly.

Let $k = \lceil \log n \rceil$. We create a range tree, where each node itself contains a balanced binary search tree (BBST), storing $\LAST$ values of its corresponding range. Formally, for $i \in [0, n/2^j)$ and $j \in [0, k]$, the $i^\textrm{th}$ node of the $j^\textrm{th}$ level of the range tree, stores $\LAST[v]$ for every $v \in (i \cdot 2^{k-j}, (i+1)\cdot 2^{k-j}]$. Denote the range tree by $\mathbf{R}$, and each BBST corresponding to the range $[a, b]$ by $\mathbf{B}_{[a,b]}$. We say that the range $[a,b]$  is \emph{canonical} if it corresponds to a range of some $\mathbf{B}_{[a,b]}$ in $\mathbf{R}$.

Again, to allow fast initialization, we make the following adjustments from the given formalization above: (1) values $\LAST[v] = 0$ are never stored in any $\mathbf{B}_{[a,b]}$, and (2) each $\mathbf{B}_{[a,b]}$ is created on-the-fly during the first occasion it becomes non-empty. Further, we augment each $\mathbf{B}_{[a,b]}$ so that each of its node maintains the size of the subtree rooted at that node: this allows us to count, in $O(\log n)$ time, the number of entries in $\mathbf{B}_{[a,b]}$ that is no smaller than a given threshold.

Observe that each $v$ is included in exactly one $\mathbf{B}_{[a,b]}$ per level in $\mathbf{R}$, so $k+1=O(\log n)$ copies of $\LAST[v]$ are stored throughout $\mathbf{R}$. Moreover, by the property of range trees, any interval can be decomposed into a disjoint union of $O(\log n)$ canonical ranges. From these properties we implement the data structure $\mathbf{R}$ to support the following operations. (Note that $\mathbf{R}$ is initially an empty tree, so initialization is trivial.)
\begin{itemize}
\item \func{count}$(v)$: compute $|T_v|$. \\
We break $(\LAST[v],w_v)$ into $O(\log n)$ disjoint canonical ranges $[a_i, b_i]$'s each corresponding to some $\mathbf{B}_{[a_i,b_i]}$, then compute $t_{[a_i,b_i]} =|\{u \in [a_i, b_i]: \LAST[u] < v\}|$, and return $\sum_i t_{[a_i,b_i]}$. The value $t_{[a_i, b_i]}$ is obtained by counting the entries of $\mathbf{B}_{[a_i, b_i]}$ that is at least $v$, then subtract it from $b_i-a_i+1$; we cannot count entries less than $v$ because $\LAST[u]=0$ are not stored.
\item \func{pick}$(v,F)$: find the $F^\textrm{th}$ minimum value in $T_v$ (assuming $F \leq |T_v|$). \\
We again break $(\LAST[v],w_v)$ into $O(\log n)$ canonical ranges $[a_i, b_i]$'s, compute $t_{[a_i, b_i]}$'s, and identify the canonical range $[a^*,b^*]$ containing the $i^\textrm{th}$ smallest element (i.e., $[a_i, b_i]$ with the smallest $b$ satisfying $\sum_{j \leq i} t_{[a_j,b_j]} \geq F$ assuming ranges are sorted). Binary-search in $[a^*,b^*]$ to find exactly the $i^\textrm{th}$ smallest element of $T$. This is ccomplished by traversing $\mathbf{R}$ starting from the range $[a^*,b^*]$ down to a leaf, at each step computing the children's $T_{[a,b]}$'s and deciding which child's range contains the desired element.
\item \func{update}$(v,u)$: simulate coin-flips, assigning $X_{vu} \leftarrow 1$, and $X_{v,u'} \leftarrow 0$ for $u' \in (\LAST[v], u) \cap T_v$. \\
This is done implicitly by handling the change $\LAST[v] \leftarrow u$: for each BBST $\mathbf{B}_{[a,b]}$ where $v \in [a, b]$, remove the old value of $\LAST[v]$ and insert $u$ instead.
\end{itemize}
It is straightforward to verify that all operations require at most $O(\log^2 n)$ time and $O(\log n)$ additional space per call. The overall implementation is given in Algorithm~\ref{alg:exact-coin-toss}, using the same asymptotic time and additional space. Recall also that sampling $F\sim\mathsf{ExactF}(p,t)$ requires $O(\log n)$ time and one $N$-bit random word for the $G(n,p)$ model.

\subsection{Data structure for \func{Vertex-Pair} queries in the Erd\"{o}s-R\'{e}nyi model}\label{sec:det-er-pair}
Recall that we define $Q$ in Algorithm~\ref{alg:oblivious-coin-toss} as the  set of pairs $(u,v)$ where $X_{uv}$ is assigned to $\ZERO$ during a \func{Vertex-Pair} query, allowing us to check for modifications of $\ADJ$ not captured by $\LAST[v]$ and $K_v$. Here in Algorithm~\ref{alg:exact-coin-toss}, rather than checking, we need to be able to count such entries. Thus, we instead create a BBST $Q'_v$ for each $v$ defined as:
\[Q'_v = \{u: u > \LAST[v], v > \LAST[u], \textrm{ and } X_{uv}\textrm{ is assigned to }\ZERO \textrm{ during a \func{Vertex-Pair} query}\}.\]
This definition differs from that of $Q$ in Section~\ref{sec:ER-pair} in two aspects. First, we ensure that each $\ADJ[v][u] = \ZERO$ is recorded by either $\LAST$ (via Lemma~\ref{lem:cond-0}) or $Q'_v$ (explicitly), but \emph{not both}. In particular, if $u$ were to stay in $Q'_v$ when $\LAST[v]$ increases beyond $u$, we would have double-counted these entries $\ZERO$ not only recorded by $Q'_v$ but also implied by $\LAST[v]$ and $K_v$. By having a BBST for each $Q'_v$, we can compute the number of $\ZERO$'s that must be excluded from $T_v$, which cannot be determined via $\LAST[v]$ and $K_v$ alone: we subtract these from any counting process done in the data structure $\mathbf{R}$.

Second, we maintain $Q'_v$ separately for each $v$ as an ordered set, so that we may identify non-neighbors of $v$ within a specific range -- this allows us to remove non-neighbors in specific range, ensuring that the first aspect holds. More specifically, when we increase $\LAST[v]$, we must go through the data structure $Q'_v$ and remove all $u < \LAST[v]$, and for each such $u$, also remove $v$ from $Q'_u$. There can be as many as linear number of such $u$, but the number of removals is trivially bounded by the number of insertions, yielding an amortized time performance guarantee in the following theorem. Aside from the deterministic guarantee, unsurprisingly, the required amount of random words for this algorithm is lower than that of the algorithm from Section~\ref{sec:reroll-cont} (given in Theorem~\ref{thm:ER-rand-iterations} and Corollary~\ref{cor:oblivious-alg}).

\begin{theorem}
Consider the Erd\"{o}s-R\'{e}nyi $G(n,p)$ model. For \func{Next-Neighbor} queries only, Algorithm~\ref{alg:exact-coin-toss} is an implementation that answers each query using $O(\log^2 n)$ time, $O(\log n)$ additional space, and one $N$-bit random word. For \func{Next-Neighbor} and \func{vertex pair} queries,an extension of Algorithm~\ref{alg:exact-coin-toss} answers each query using $O(\log^2 n)$ amortized time, $O(\log n)$ additional space, and one $N$-bit random word.
\end{theorem}

\subsection{Data structure for the Stochastic Block model}\label{sec:det-sbm}

We employ the data structure for generating and counting the number of vertices of each community in a specified range from Section~\ref{sec:application_sbm}. We create $r$ different copies of the data structure $\mathbf{R}$ and $Q'_v$, one for each community, so that we may implement the required operations separately for each color, including using the \func{count} subroutine to sample $F\sim\mathsf{ExactF}$ via the corresponding CDF, and picking the next neighbor according to $F$. Recall that since we do not store $\LAST[v] = 0$ in $\mathbf{R}$, and we only add an entry to $K_v$, $P_v$ or $Q'_v$ after drawing the corresponding $X_{uv}$, the communities of the endpoints, which cover all elements stored in these data structures, must have already been determined. Thus, we obtain the following corollary for the Stochastic Block model.

\begin{restatable}{corollary}{res:sbm-corol}
Consider the Stochastic Block model with randomly-assigned communities. For \func{Next-Neighbor} queries only, Algorithm~\ref{alg:exact-coin-toss} is an implementation that answers each query using $O(r\,\poly(\log n))$ time, random words, and additional space per query. For \func{Next-Neighbor} and \func{Vertex-Pair} queries, Algorithm~\ref{alg:exact-coin-toss} answers each query using $O(r\,\poly(\log n))$ amortized time, $O(r\,\poly(\log n))$ random words, and $O(r\,\poly(\log n))$ additional space per query additional space, and one $N$-bit random word.
\end{restatable}

