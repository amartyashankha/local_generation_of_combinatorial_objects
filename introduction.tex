\section{Introduction}

The problem of computing local information of huge random objects was pioneered in \cite{huge_old,huge}.
Further work of \cite{sparse} considers the generation of sparse random $G(n,p)$ graphs from the Erd\"{o}s-R\'{e}nyi model \cite{er},
with $p = O(\poly(\log n)/n)$, which answers $\poly(\log n)$ \func{All-Neighbors} queries, listing the neighbors of queried vertices.
While these generators use polylogarithmic resources over their entire execution,
they generate graphs that are  only guaranteed to {\em appear random} to algorithms that inspect a {\em limited portion} of the generated graph.
For example, the greedy routing algorithm on Kleinberg's small world networks \cite{kleinberg} only uses $\mathcal O(\log^2 n)$ probes.
Using our implementation, one can execute this algorithm on a random small world instance
in $\mathcal O(\poly(\log n))$ time without incurring the $\mathcal O(n)$ prior-sampling overhead.

In \cite{reut}, the authors construct an oracle for the generation of recursive trees, and BA preferential attachment graphs.
Unlike \cite{sparse}, their implementation allows for an arbitrary number of queries.
This result is particularly interesting --  although the graphs in this model are generated via a sequential process,
the oracle is able to locally generate arbitrary portions of it and answer queries in polylogarithmic time.
Though preferential attachment graphs are sparse, they contain vertices of high degree,
thus \cite{reut} provides access to the adjacency list through \func{Next-Neighbor} queries.
\todo{Segway}



\subsection{Undirected Graphs}
\label{sec:undirected_graphs}
In Section~\ref{sec:undirected}, we implement queries to both the adjacency matrix and adjacency list representation
for the generic class of \emph{undirected graphs} with {\em independent edge probabilities} $\left\{ p_{uv} \right\}_{u,v\in V}$,
where $p_{uv}$ denotes the probability that there is an edge between $u$ and $v$.
Throughout, we identify our vertices via their unique IDs from $1$ to $n$, namely $V = [n]$.
We implement \func{Vertex-Pair}, \func{Next-Neighbor}, and \func{Random-Neighbor}
\footnote{\func{Vertex-Pair}$(u,v)$ returns whether $u$ and $v$ are adjacent, \func{Next-Neighbor}$(v)$ returns a new neighbor of $v$ each time
it is invoked (until none is left), and \func{Random-Neighbor}$(v)$ returns a uniform random neighbor of $v$ (if $v$ is not isolated).} queries.
Under reasonable assumptions on the ability to compute certain values pertaining to consecutive edge probabilities,
our implementations support all three types of queries using $\mathcal{O}(\poly(\log n))$ time, space, and random bits.
In particular, our construction yields local-access generators for the Erd\"{o}s-R\'{e}nyi $G(n,p)$ model (for \emph{all} values of $p$),
and the Stochastic Block model with random community assignment.
As in \cite{reut} (and unlike the generators in \cite{huge_old,huge,sparse}), our techniques allow unlimited queries.

While \func{Vertex-Pair} and \func{Next-Neighbor} queries, as well as \func{All-Neighbors} queries for sparse graphs,
have been considered in the prior works of \cite{reut, huge_old, huge, sparse}, we provide the first implementation (to the best of our knowledge)
of \func{Random-Neighbor} queries, which do not follow trivially from the \func{All-Neighbor} queries in \emph{non-sparse graphs}.
Such queries are useful, for instance, for sub-linear algorithms that employ random walk processes.
\func{Random-Neighbor} queries present particularly interesting challenges that are outlined below.

\paragraph*{\func{Next-Neighbor} Queries}
\label{par:next_neighbor_queries}
We note that the next neighbor of a vertex can be found trivially by generating consecutive entries of the adjacency matrix,
but for small edge probabilities $p_{uv} = o(1)$ this implementation can be too slow.
In our algorithms, we achieve speed-up by sampling multiple neighbor values at once for a given vertex $u$; more specifically,
we sample for the number of ``non-neighbors'' preceding the next neighbor.
To do this, we assume that we have access to an oracle which can estimate the ``skip'' probabilities $F(v,a,b)=\prod^{b}_{u=a} (1-p_{v,u})$,
where $F(v,a,b)$ is the probability that $v$ has no neighbors in the range $[a,b]$.
We later show that it is possible to compute this quantity efficiently for the $G(n,p)$ and Stochastic block models.

A main difficulty in our setup, as compared to \cite{reut}, arises from the fact that our graph is undirected, and thus
we must design a data structure that ``informs'' all (potentially $\Theta(n)$) non-neighbors once we decide on the query vertex's next neighbor.
%Unlike in the case of directed graphs, each $\func{Next-Neighbor}$ query
%can affect the probabilities of a large number of other vertices.
More concretely, if $u'$ is sampled as the next neighbor of $v$ after its previous neighbor $u$,
we must maintain consistency in subsequent steps by ensuring that none of the vertices in the range $(u,u')$ return $v$ as a neighbor.
This update will become even more complicated as we later handle \func{Random-Neighbor} queries, where we may generate non-neighbors at random locations.

In Section~\ref{sec:ER-rand}, we present a very simple randomized generator (Algorithm~\ref{alg:oblivious-coin-toss})
that supports \func{Next-Neighbor} queries efficiently, albeit the analysis of its performance is rather complicated.
We remark that this approach may be extended to support \func{Vertex-Pair} queries with superior performance
(given that we do not to support \func{Random-Neighbor} queries) and to provide deterministic resource usage guarantee
\todo{What is deterministic here?}
-- the full analysis can be found in Section~\ref{sec:reroll-cont} and \ref{sec:ER-det}, respectively.

\paragraph*{\func{Random-Neighbor} Queries}
\label{par:random_neighbor_queries}

We provide efficient \func{Random-Neighbor} queries (Section~\ref{sec:buckets}).
The ability to do so is surprising since:
(1) \func{Random-Neighbor} queries affect the conditional probabilities of the remaining neighbors in a non-trivial manner
\footnote{\label{conditional}Consider a $G(n,p)$ graph with small $p$, say $p = 1/\sqrt n$,
such that vertices will have $\tilde{\mathcal{O}}(\sqrt n)$ neighbors with high probability.
After $\tilde{\mathcal{O}}(\sqrt n)$ \func{Random-Neighbor} queries, we will have uncovered all the neighbors (w.h.p.),
so that the conditional probability of the remaining $\Theta(n)$ edges should now be close to zero.}, and
(2) our implementation does not resort to explicitly sampling the degree of any vertex $v$
in order to generate a random neighbor with the correct probability $\frac{1}{d_v}$.
First, even without committing to the degrees, answers to \func{Random-Neighbor} queries
affect the conditional probabilities of the remaining adjacencies in a global and non-trivial manner \footref{conditional}
-- that is, from the point of view of the \emph{agent} interacting with the generator.
Second, sampling the degree of the query vertex, we suspect, is not viable for \emph{sub-linear} generators,
because this quantity alone imposes dependence on the existence of \emph{all} of its potential incident edges.
Therefore, our generator needs to return a random neighbor, with probability reciprocal to the query vertex's degree,
without resorting to ``knowing'' its degree.
The generator, however, must somehow maintain and leverage its additional \emph{internal knowledge}
of the partially-generated graph, to keep its computation tractable throughout the entire graph generation process.
This requires a way of implicitly keeping track of all the resulting changes.

We formulate a {\em bucketing approach} (Section~\ref{sec:buckets})
which samples multiple consecutive edges at once, in such a way
that the conditional probabilities of the unsampled edges
remain independent and ``well-behaved'' during subsequent queries.
For each vertex $v$, we divide the vertex set (potential neighbors) or $v$ into consecutive ranges (buckets),
so that each bucket contains, in expectation, roughly the same number of neighbors
$\sum^{b}_{u=a} p_{v,u}$ (which we must be able to compute efficiently).
The subroutine of \func{Next-Neighbor} may be applied to sample the neighbors within a bucket in expected constant time.
Then, one may obtain a random neighbor of $v$ by picking a random neighbor from a random bucket;
probabilities of picking any neighbors may be normalized to the uniform distribution via rejection sampling,
while stilling yielding $\poly(\log n)$ complexities overall.
This bucketing approach also naturally leads to our data structure that requires
constant space for each bucket and for each edge, using $\Theta(n+m)$ overall memory requirement.
The \func{Vertex-Pair} queries are implemented by sampling the relevant bucket.

We now consider the application of our construction above to actual random graph models,
where we must realize the assumption that $\prod^{b}_{u=a} (1-p_{v,u})$
and $\sum^{b}_{u=a} p_{v,u}$ can be computed efficiently.
This holds trivially for the $G(n,p)$ model via closed-form formulas,
but requires an additional back-end data structure for the Stochastic Block models.

\paragraph*{Erd\"{o}s-R\'{e}nyi}
\label{par:erdos_renyi}
In Section~\ref{sec:app_er}, we apply our construction to random $G(n,p)$ graphs for
arbitrary $p$, and obtain
$\func{Vertex-Pair}$, $\func{Next-Neighbor}$, and $\func{Random-Neighbor}$ queries,
using polylogarithmic resources (time, space and random bits) per query.
We remark that, while $\Omega(n+m) = \Omega(p n^2)$ time and space
is clearly necessary to generate and represent a full random graph,
our implementation supports local-access via all three types of queries, 
and yet can generate a full graph in $\widetilde{O}(n+m)$ time and space (Corollary~\ref{thm:er-optimal}),
which is tight up to polylogarithmic factors.

%{\color{red}
\paragraph*{Stochastic Block Model}
\label{par:stochastic_block_model}
We generalize our construction to the Stochastic Block Model.
In this model, the vertex set is partitioned into $r$ \emph{communities}
$\left\{ C_1, \ldots, C_r \right\}$.
The probability that an edge exists depends on the communities of its endpoints:
if $u\in C_i$ and $v \in C_j$, then $\{u,v\}$ exists with probability $p_{i,j}$,
given in an $r\times r$ matrix $\matr{P}$.
As communities in the observed data are generally unknown a priori,
and significant research has been devoted to designing efficient algorithm
for community detection and recovery,
these studies generally consider the \emph{random community assignment} condition for the purpose of designing and analyzing algorithms (see e.g., \cite{mossel2015reconstruction}).
Thus, in this work, we aim to construct generators for this important case, where the community assignment of vertices are independently sampled from some given distribution $\distr{R}$.
%}

Our approach is, as before, to sample for the next neighbor or a random neighbor directly,
although our result does not simply follow closed-form formulas,
as the probabilities for the potential edges now depend
on the communities of endpoints.
To handle this issue, we observe that it is sufficient to efficiently count
the number of vertices of each community in any
range of contiguous vertex indices.
We then design a data structure extending a construction of \cite{huge},
which maintain these counts for ranges of vertices,
and ``sample'' the partition of their counts only on an as-needed basis.
This extension results in an efficient technique to sample counts
from the \emph{multivariate hypergeometric distribution} (Section~\ref{sec:multivariate_hypergeometric_sampling}).
This sampling procedure may be of independent interest.
For $r$ communities, this yields an implementation with
$ \mathcal{O}(r\cdot \poly(\log n))$ overhead in required resources for each operation.
This upholds all previous polylogarithmic guarantees when $r = \poly(\log n)$.

\paragraph*{CDF Based Sampling}
It is worth noting that our techniques for implementing local-access for the ER and SBM graphs
can easily be extended to other similar models of random graphs.
The only requirement is that the CDF of the probability sequences can be efficiently computed as in Section~\ref{para:CDF}.





\subsection{Directed Graphs}
\label{sec:directed_graphs}
We then consider local-access generators for directed graphs in Kleinberg's Small World model.
In this case, the probabilities are based on distances in a 2-dimensional grid.
Using a modified version of our previous sampling procedure, we present such a generator supporting \func{All-Neighbors} queries in
$\mathcal{O}(\poly(\log n))$ time, space and random bits per query (since such graphs are sparse, the other queries follow directly).
\todo{This is duplicate}

Lastly, we consider Kleinberg's Small World model (\cite{kleinberg, klein}) in Section~\ref{sec:small_world}.
While Small-World models are proposed to capture 
properties of observed data such as small shortest-path 
distances and large clustering coefficients \cite{watts1998collective}, 
this important special case of Kleinberg's model, defined on two-dimensional grids, 
demonstrates underlying geographical structures of networks. 
The vertices are aligned on a $\sqrt{n}\times\sqrt{n}$ grid,
and the edge probabilities are a function of a two-dimensional distance metric.
Since the degree of each vertex in this model is $\Bo(\log n)$ with high probability,
we design generators supporting \func{All-Neighbor} queries.
%In contrast to our previous cases, this model imposes an underlying
%two-dimensional structure of the vertex set, which governs
%the distance function as well as complicates the individual edge probabilities.




\subsection{Catalan Objects}%
\label{sec:catalan_objects}
We also consider the problem of sampling of very long ($2n$ step) one dimensional random walks,
One obvious query of interest is $\func{Height}(t)$ which returns the position of the walk at time $t$.
\func{Height} queries for the simple unconstrained random walk
follow trivially from the implementation of interval summable functions presented in \cite{huge}.
Instead, we focus on an important generalization by considering balanced random walks (equal number of up and down steps)
that are constrained to be always positive (commonly known as Dyck Paths).
The added constraint introduces complicated non-local dependencies on the distribution of positions.
However, we are able to support both queries using $\mathcal O(\poly(\log n))$ resources.

Dyck paths are one type of Catalan object, and they have natural bijections to other Catalan objects
such as bracketed expressions, random rooted trees and binary trees
Thus, we can use our Dyck Path implementation to obtain useful implementations of other random Catalan objects.
For instance, $\func{Height}$ queries correspond to $\func{Depth}$ queries on rooted trees and bracketed expressions
(Section~\ref{sec:bijections_to_other_catalan_objects}).

However, we might want to support more interesting qaueries; for example,
finding the children of a node in a random tree or finding the matching bracket in a random bracketed expression.
To achieve this, we will also support \func{First-Return} queries
where $\func{First-Return}(t)$ returns the first time when the random walk returns to the same level as it was at time $t$.
In Section~\ref{sec:bijections_to_other_catalan_objects}, we will see that $\func{First-Return}$ queries correspond to
$\func{Next-Neighbor}$ queries on trees and $\func{Matching-Bracket}$ queries on bracketed expressions.





\subsection{Random Coloring of Graphs}%
\label{sec:random_coloring_of_graphs}
Finally, we introduce a new model for implementating huge random objects with \emph{huge description size}.
In this model, we implement query access to random $q$-colorings of arbitrary graphs with maximum degree $\Delta$.
A random coloring is sampled by proposing $\mathcal O(n\log n)$ color updates and accepting the ones that do not create a conflict (Glauber dynamics).
This is an inherently sequential process with the acceptance of a particular proposal depending on all preceding neighboring proposals.
Moreover, unlike the previously considered random objects, this one has no succint representation,
and we can only uncover the proper distribution by probing the graph (in the manner of \emph{local computation algorithms} \cite{LCA}).
Unlike LCAs which have to return \emph{some} valid solution, we also have to make sure that we return a solution from the correct distribution.
We are able to construct an efficient implementation that returns the final color of a vertex using only a sub-linear number of probes when $q>12\Delta$.

For additional related work, see Section~\ref{sec:related_work}.
