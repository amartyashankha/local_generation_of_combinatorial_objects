\section{Introduction}
Consider an algorithm performing a computation on a \emph{huge random object} (for example a random graph or a ``long'' random walk).
Is it necessary to generate the entire object prior to the computation,
or is it possible to provide query access to the object and sample it incrementally ``on-the-fly'' (as requested by the algorithm)?
Such an \emph{implementation} would emulate the random object by answering appropriate queries in a consistent manner.
Specifically, all responses to queries must be consistent with an instance of the random object sampled from the true distribution (or close to it).
This paradigm is useful when the algorithm is sub-linear and thus, sampling the entire object up front would ruin its efficiency.
For example, the greedy routing algorithm on Kleinberg's small world networks \cite{kleinberg} only uses $\mathcal O(\log^2 n)$ probes.
Using our implementation, one can execute this algorithm on a random small world instance
in $\mathcal O(\poly(\log n))$ time without incurring the $\mathcal O(n)$ prior-sampling overhead.

The problem of sampling partial information about huge random objects was pioneered in \cite{huge_old,huge}.
Further work in \cite{sparse,reut} considers the generation of different random graph models.
\todo[inline,color=Red!20]{Add more citations}
\todo[inline,color=Red!20]{In this paper, we . . . Finish}
One emerging theme that we develop further in this work is to provide common data-structure query access to huge random objects.
For example, for random graph implementations, in addition to supporting adjacency matrix queries about the existence of edge $(u,v)$,
\cite{reut} introduced the study of $\func{Next-Neighbor}$ queries which provide efficient access to the adjacency list representation.





\subsection{Random Graphs}%
\label{sec:random_graphs}
In Section~\ref{sec:undirected}, we implement queries to both the adjacency matrix and adjacency list representation
for the generic class of \emph{undirected graphs} with {\em independent edge probabilities} $\left\{ p_{uv} \right\}_{u,v\in V}$,
where $p_{uv}$ denotes the probability that there is an edge between $u$ and $v$.
We implement \func{Vertex-Pair}, \func{Next-Neighbor}, and \func{Random-Neighbor}
\footnote{\func{Vertex-Pair}$(u,v)$ returns whether $u$ and $v$ are adjacent, \func{Next-Neighbor}$(v)$ returns a new neighbor of $v$ each time
it is invoked (until none is left), and \func{Random-Neighbor}$(v)$ returns a uniform random neighbor of $v$ (if $v$ is not isolated).} queries.
Under reasonable assumptions on the ability to compute certain values pertaining to consecutive edge probabilities,
our implementations support all three types of queries using $\mathcal{O}(\poly(\log n))$ time, space, and random bits.
Note that in this setting, $\func{Vertex-Pair}$ queries are trivial, since the existence of an edge depends on an independent random variable.
As in \cite{reut} (and unlike many of the implementations presented in \cite{huge_old,huge}), our techniques allow unlimited queries.
In particular, our construction yields local-access implementations for the Erd\"{o}s-R\'{e}nyi $G(n,p)$ model (for \emph{all} values of $p$),
and the Stochastic Block model with random community assignment.
\input{graph_results_table}

While \func{Vertex-Pair} and \func{Next-Neighbor} queries, as well as \func{All-Neighbors} queries for sparse graphs,
have been considered in the prior works of \cite{reut, huge_old, huge, sparse},
we provide the first implementations of non-sparse random graph models.
Prior results for implementing queries to $G(n,p)$ focused on the sparse case where $p = \log^{\mathcal O(1)} n/n$ \cite{sparse}.
The dense case where $p = \Theta(1)$ is also relatively simple because most of the adjacency matrix is filled,
and neighbor queries can be answered by performing $\Theta(1)$ \func{Vertex-Pair} queries until an edge is found.
The interesting case is when $p$ takes on some intermediate value; say $p = 1/\sqrt{n}$.
In this regime, each vertex has high degree $\mathcal O(\sqrt{n})$ but most of the adjacency matrix is empty,
thus making it difficult to sample a neighbor efficiently.
We also provide the first implementation (to the best of our knowledge) of \func{Random-Neighbor} queries in \emph{non-sparse graphs}.
Such queries are useful, for instance, in sub-linear algorithms that employ random walk processes.


\paragraph*{Directed Random Graphs: The Small World Model}
\label{par:directed_random_graphs}
We then consider local-access implementations for directed graphs in Kleinberg's Small World model,
where the probabilities are based on distances in a 2-dimensional grid.
Building on our previous sampling procedure, we implement \func{All-Neighbors} queries for the Small World model,
using $\mathcal{O}(\poly(\log n))$ time, space and random bits (since such graphs are sparse, the other queries follow directly).




\subsection{Catalan Objects}%
\label{sec:intro_catalan_objects}
We show how to provide query access to very long ($2n$ step) one dimensional random walks,
One obvious query of interest is $\func{Height}(t)$ which returns the position of the walk at time $t$.
We also introduce and support \func{First-Return} queries, where $\func{First-Return}(t)$ returns
the first time when the random walk returns to the same level as it was at time $t$.
\func{Height} queries for the simple unconstrained random walk
follow trivially from the implementation of interval summable functions presented in \cite{huge}.
Here, we focus on an important generalization by considering balanced random walks (equal number of up and down steps) on the integer line,
that are constrained to be always positive (commonly known as Dyck Paths).
The added constraint introduces intricate non-local dependencies on the distribution of positions.
However, we are able to support both queries using $\mathcal O(\poly(\log n))$ resources.

Dyck paths are one type of Catalan object, and they have natural bijections to other Catalan objects
such as bracketed expressions, random rooted trees and binary trees.
Thus, we can use our Dyck Path implementation to obtain useful implementations of other random Catalan objects.
For instance, $\func{Height}$ queries correspond to $\func{Depth}$ queries on rooted trees and bracketed expressions
(Section~\ref{sec:bijections_to_other_catalan_objects}).
We also support more involved queries that are widely used; for example, finding the children of a node in a random tree
or finding the matching bracket in a random bracketed expression.
To achieve this, we note that \func{First-Return} queries queries correspond to $\func{Next-Neighbor}$ queries on trees,
and $\func{Matching-Bracket}$ queries on bracketed expressions (Section~\ref{sec:bijections_to_other_catalan_objects}).




\subsection{Random Coloring of Graphs}%
\label{sec:random_coloring_of_graphs}
Finally, we introduce a new model for implementating huge random objects with \emph{huge input description};
that is, the distribution is specified as a uniformly random solution to a huge combinatorial problem.
In this model, we implement query access to random $q$-colorings of a given huge graph $G$ with maximum degree $\Delta$.
A random coloring is sampled by proposing $\mathcal O(n\log n)$ color updates and accepting the ones that do not create a conflict (Glauber dynamics).
This is an inherently sequential process with the acceptance of a particular proposal depending on all preceding neighboring proposals.
Moreover, unlike the previously considered random objects, this one has no succinct representation, and we can only uncover the proper distribution
by probing the graph (in the manner of \emph{local computation algorithms} \cite{LCA, LCA_space_efficient}).
Unlike LCAs which have to return \emph{some} valid solution, we also have to make sure that we return a solution from the correct distribution.
We are able to construct an efficient oracle that returns the final color of a vertex using only a sub-linear number of probes when $q\ge 7\Delta$.




\subsection{Related Work}
\label{sec:related_work}
The problem of computing local information of huge random objects was pioneered in \cite{huge_old,huge}.
Further work of \cite{sparse} considers the generation of sparse random $G(n,p)$ graphs from the Erd\"{o}s-R\'{e}nyi model \cite{er},
with $p = O(\poly(\log n)/n)$, which answers $\poly(\log n)$ \func{All-Neighbors} queries, listing the neighbors of queried vertices.
While these implementations use polylogarithmic resources over their entire execution,
they generate graphs that are  only guaranteed to \emph{appear random} to algorithms that inspect a \emph{limited portion} of the generated graph.

In \cite{reut}, the authors construct an oracle for the generation of recursive trees, and BA preferential attachment graphs.
Unlike prior work, their implementation allows for an arbitrary number of queries.
This result is particularly interesting --  although the graphs in this model are generated via a sequential process,
the oracle is able to locally generate arbitrary portions of it and answer queries in polylogarithmic time.
Though preferential attachment graphs are sparse, they contain vertices of high degree,
thus \cite{reut} provides access to the adjacency list through \func{Next-Neighbor} queries.

For additional related work, see Section~\ref{sec:related_work}.
