\subsection{Final Implementation Using Blocks}
\label{sec:blocks}
We begin this section by focusing first on \func{Random-Neighbor} queries, then extend the construction to the remaining ones.
In order to handle \func{Random-Neighbor}$(v)$, we divide the neighbors of $v$ into \emph{blocks} $\vec B_v = \{ B^{(i)}_v, B^{(i)}_v,\ldots\}$,
so that each block contains, in expectation, roughly the same number of neighbors of $v$.
We implement \func{Random-Neighbor}$(v)$ by randomly selecting a block $B^{(i)}_v$,
filling in entries $\ADJ[v][u]$ for $u \in B^{(i)}_v$ with $\ONE$'s and $\ZERO$'s, and then reporting a random neighbor from this block.
As the block size may be large when the probabilities are small, instead of using a linear scan,
our \func{Fill} subroutine will be implemented using the ``run-of-$\ZERO$s'' sampling from  Algorithm~\ref{alg:oblivious-coin-toss}
(see Section~\ref{sec:ER-rand}).
Since the number of iterations required by this subroutine is roughly proportional to the number of neighbors,
we choose to allocate a constant number of neighbors in expectation to each block:
with constant probability the block contains some neighbors, and with high probability it has at most $O(\log n)$ neighbors.

Nonetheless, as the actual number of neighbors appearing in each block may be different,
we balance out these discrepancies by performing \emph{rejection sampling}, equalizing the probability of choosing any neighbor implicitly,
again without the knowledge of $\deg(v)$.
Leveraging the fact that the maximum number of neighbors in any block is $\Bo(\log n)$,
we show not only that the probabability of success in the rejection sampling process is at least $1/\poly(\log n)$,
but the number of iterations required by \func{Next-Neighbor} is also bounded by $\poly(\log n)$, achieving the overall $\poly(\log n)$ complexities.
Here in this section, we will extensively rely on the assumption that the expected number of neighbors for consecutive vertices,
$\sum_{u=a}^b p_{vu}$, can be approximated efficiently.

\subsubsection{Partitioning and Filling the Blocks}
\label{sec:block_partitioning_and_filling}
We fix some sufficiently large constant $L$, and assign the vertex $u$ to the $\lceil\sum^{u}_{i=1} p_{vi}/L\rceil^\textrm{th}$ block of $v$.
Essentially, each block represents a contiguous range of vertices, where the expected number of neighbors of $v$ in the block is in $[L-1,L+1]$
(for example, for $G(n,p)$, each block contains roughly $L/p$ vertices).
Let us define $\Gamma^{(i)}(v) = \Gamma(v) \cap B^{(i)}_v$, the actual neighbors appearing in block $B^{(i)}_v$.
Our construction ensures that $L-1 < \mathbb E \left[|\Gamma^{(i)}(v)|\right] < L+1$ for every $i < |\vec B_v|$
(i.e., the condition holds for all blocks except possibly the last one).

Now, we show that with high probability, all the block sizes $|\Gamma^{(i)}(v)|=\mathcal{O}(\log n)$, and at least a $1/3$-fraction of the blocks are non-empty (i.e., $|\Gamma^{(i)}(v)|>0$), via the following lemmas (proven in Section~\ref{sec:undirected_omitted}).

\begin{restatable}{lemma}{MaxBlockSize}
\label{lem:MaxBlockSize}
With high probability, the number of neighbors in every block, $|\Gamma^{(i)}(v)|$, is at most $ \mathcal{O}(\log n)$.
\end{restatable}

\begin{restatable}{lemma}{EmptyBlock}
\label{lem:EmptyBlock}
With high probability, for every $v$ such that $|\vec B_v| = \Omega(\log n)$ (i.e., $\mathbb E = \Omega(\log n)$), at least a $1/3$-fraction of the blocks $\{B^{(i)}_v\}_{i\in[|\vec B_v|]}$ are non-empty.
\end{restatable}

We consider blocks to be in two possible states -- \filled~or \unfilled. Initially, all blocks are considered \unfilled.
In our algorithm we will maintain, for each block $B^{(i)}_v$, the set $P^{(i)}_v$ of known neighbors of $u$ in block $B^{(i)}_v$;
this is a refinement of the set $P_v$ in Section~\ref{sec:ER-rand}.
We define the behaviors of the procedure $\func{Fill}(v,i)$ as follows.
When invoked on an unfilled block $B^{(i)}_v$, $\func{Fill}(v,i)$ decides whether each vertex $u \in B^{(i)}_v$ is a neighbor of $v$
(implicitly setting $\ADJ[v][u]$ to $\ONE$ or $\ZERO$) unless $X_{vu}$ is already decided; in other words, update $P_v^{(i)}$ to $\Gamma^{(i)}(v)$.
Then $B^{(i)}_v$ is marked as \filled.
We postpone the description of our implementation of $\func{Fill}$ to Section~\ref{sec:fill_implement}, instead using it as a black box.





\subsubsection{Putting it all together: \func{Random-Neighbor} queries}
\label{sec:random_neighbor}
\begin{wrapfigure}[11]{R}{0.41\textwidth}
\vspace{-1.0em}
\begin{framed}
    \renewcommand\figurename{Algorithm}
    \caption{Block sampling.}
    \label{alg:random}
    \begin{algorithmic}
        \Procedure{Random-Neighbor}{$v$}
            \While{True}
                \State{\textbf{sample} $B^{(i)}_v \thicksim_{\mathcal U} \vec B_v$ u.a.r.}
                \If {$B^{(i)}_v$ is not \emph{filled}}
                    \State$\func{Fill}\left( v,i\right)$
                \EndIf
                \State{\textbf{with probability} $\frac{|P_v^{(i)}|}{M}$}
                    \State{\hspace{\algorithmicindent}\Return $u\thicksim_{\mathcal U} P_v^{(i)}$ u.a.r }
            \EndWhile
        \EndProcedure
    \end{algorithmic}
\end{framed}
\end{wrapfigure}

Consider Algorithm~\ref{alg:random} for sampling a random neighbor via rejection sampling.
For simplicity, throughout the analysis, we assume $|\vec B_v| = \Omega(\log n)$;
otherwise, invoke $\func{Fill}(v,i)$ for all $i \in [|\vec B_v|]$ to obtain the entire neighbor list $\Gamma(v)$.

To obtain a random neighbor, we first choose a block $B^{(i)}_v$ uniformly at random, and invoke $\func{Fill}(v,i)$ if the block is \emph{unfilled}.
Then, we \emph{accept} the sampled block for generating our random neighbor with probability proportional to $|P_v^{(i)}|$.
More specifically, if $M = \Theta(\log n)$ is an upper bound on the maximum number of neighbors in any block (see Lemma~\ref{lem:MaxBlockSize}),
we accept block $B^{(i)}_v$ with probability $|P_v^{(i)}|/M$, which is well-defined (i.e., does not exceed $1$) with high probability.
Note that if $P_v^{(i)} = \emptyset$, we sample another block.
If we choose to accept $B^{(i)}_v$, we return a random neighbor from $P_v^{(i)}$.
Otherwise, \emph{reject} this block and repeat the process again.

Since the returned vertex is always a member of $P_v^{(i)}$, a valid neighbor is always returned.
We now show that the algorithm correctly samples a uniformly random neighbor
and bound the number of iterations required for the rejection sampling process.
\begin{restatable}{lemma}{rand-gen-correct}
\label{lem:rand_gen_correct}
Algorithm~\ref{alg:random} returns a uniformly random neighbor of vertex $v$.
\end{restatable}
\begin{proof}
It suffices to show that the probability that any neighbor in $\Gamma(v)$ is return with uniform positive probability, within the same iteration.
Fixing a single iteration and consider a vertex $u\in P_v^{(i)}$, we compute the probability that $u$ is accepted.
The probability that $B^{(i)}_vi$ is chosen is $1/|\vec B_v|$, the probability that $B^{(i)}_v$ is accepted is $|P_v^{(i)}|/M$,
and the probability that $u$ is chosen among $P_v^{(i)}$ is $1/|P_v^{(i)}|$.
Hence, the overall probability of returning $u$ in a single iteration
of the loop is $1/(|\vec B_v|\cdot M)$, which is positive and independent of $u$.
Therefore, each vertex is returned with the same probability.
\end{proof}

\begin{restatable}{lemma}{rand-gen-fast}
\label{lem:rand_gen_fast}
Algorithm~\ref{alg:random} terminates in $\mathcal{O}(\log n)$ iterations in expectation, or $\mathcal{O}(\log^2 n)$ iterations with high probability.
\end{restatable}
\begin{proof}
From Lemma~\ref{lem:EmptyBlock}, a $(1/3)$-fraction of the blocks are non-empty with high probability,
and hence the probability of choosing a non-empty block is at least $1/3$.
Since $M = \Theta(\log n)$ by Lemma~\ref{lem:MaxBlockSize}, the success probability of each iteration is at least $1/(3M)=\Omega(1/\log n)$,
Thus, the number of iterations required is $O(\log^2 n)$ with high probability.
\end{proof}





\subsection{Implementation of \func{Fill}}
\label{sec:fill_implement}

\begin{wrapfigure}[13]{R}{0.39\textwidth}
\vspace{-1.5em}
\begin{framed}
    \renewcommand\figurename{Algorithm}
    \caption{Filling a block}
    \label{alg:fill}
    \begin{algorithmic}
    \Procedure{Fill}{$v,i$}
    \State{$(a,b) \gets B^{(i)}_j$}
    %	\State{$w_v \gets \min \{(P_v \cap (u, n]) \cup \{n+1\}\}$}
    %    \For{$b$ in $P_v^{(i)}\cup\{\END(v,i)\}$}
            \While{$a \ge b$}
                \State{\textbf{sample} $u\sim\mathsf{F}(v,a,b)$}
                \State{$B_u^{(j)} \gets$ block containing $v$}
    %            \State{$j\gets \BLOCK(u,v)$}
                \If{$B_u^{(j)}$ is not \filled}
                    \State{$P_v^{(i)}\gets P_v^{(i)}\cup\{u\}$}
                    \State{$P_u^{(j)}\gets P_u^{(j)}\cup\{v\}$}
                \EndIf
                \State{$a \gets u$}
            \EndWhile
            \State{\textbf{mark} $B_u^{(j)}$ as \filled}
    %        \State \Return $P_v^{(i)}$
    %    \EndFor
    \EndProcedure
    \end{algorithmic}
\end{framed}
\end{wrapfigure}

Lastly, we describe the implementation of the $\func{Fill}$ procedure, employing the approach of skipping non-neighbors, as developed for Algorithm~\ref{alg:oblivious-coin-toss}. We aim to simulate the following process: perform coin-tosses $C_{vu}$ with probability $p_{vu}$ for every $u \in B^{(i)}_v$ and update $\ADJ[v][u]$'s according to these coin-flips unless they are decided (i.e., $\ADJ[v][u] \neq \PHI$). We directly generate a sequence of $u$'s where the coins $C_{vu} = \ONE$, then add $u$ to $P_v$ and vice versa if $X_{vu}$ has not previously been decided. Thus, once $B^{(i)}_v$ is \filled, we will obtain $P_v^{(i)} = \Gamma^{(i)}(v)$ as desired.

As discussed in Section~\ref{sec:ER-rand}, while we have recorded all occurrences of $\ADJ[v][u]=\ONE$ in $P_v^{(i)}$,
we need and efficient way of checking whether $\ADJ[v][u] = \ZERO$ or $\PHI$. In Algorithm~\ref{alg:oblivious-coin-toss},
$\LAST$ serves this purpose by showing that $\ADJ[v][u]$ for all $u \leq \LAST[v]$ are decided as shown in Lemma~\ref{lem:cond-0}.
Here instead, with our block structure, we maintain a single bit marking whether each block is \filled~or \unfilled:
a \filled~block implies that $\ADJ[v][u]$ for all $u \in B^{(i)}_v$ are decided.
The block structure along with mark bits, unlike $\LAST$, are capable of handling intermittent ranges of intervals,
namely blocks, which is sufficient for our purpose, as shown in the following lemma.
This yields the implementation Algorithm~\ref{alg:fill} for the $\func{Fill}$ procedure
fulfilling the requirement previously given in Section~\ref{sec:block_partitioning_and_filling}. 

\begin{restatable}{lemma}{cond}\label{lem:cond-0-fill}
The data structures $P_v^{(i)}$'s and the block marking bits together provide a succinct representation of $\ADJ$ as long as modifications to $\ADJ$ are performed solely by the \func{Fill} operation in Algorithm~\ref{alg:fill}. In particular, let $u \in B^{(i)}_v$ and $v \in B_u^{(j)}$. Then, $\ADJ[v][u]=\ONE$ if and only if $u \in P_v^{(i)}$. Otherwise, $\ADJ[v][u]=\ZERO$ when at least one of $B^{(i)}_v$ or $B_u^{(j)}$ is marked as \filled. In all remaining cases, $\ADJ[v][u]=\PHI$.
\end{restatable}
\begin{proof}
The condition for $\ADJ[v][u]=\ONE$ still holds by constuction. Otherwise, observe that $\ADJ[v][u]$ becomes decided precisely during a \func{Fill}$(v,i)$ or a \func{Fill}$(u,j)$ operation, which thereby marks one of the corresponding blocks as \filled.
\end{proof}


%More formally, let $u \in B^{(i)}_v$ and $v \in B_u^{(j)}$. Similarly to For $\ADJ[v][u] \neq \ONE$ (i.e., $u \notin B^{(i)}_v$ and $v \notin B_u^{(i)}$), we maintain the following invariant: $\ADJ[v][u]\neq \PHI$ if and only if at least one of $B^{(i)}_v$ or $B_u^{(j)}$ is \filled. Ensuring this invariant is very simple for Algorithm~\ref{alg:random}: fill an entire block at a time. Thus, we obtain the following criteria for computing $\ADJ[v][u]$ while filling $B^{(i)}_v$: if $u \in P_v$ then $\ADJ[v][u]=\ONE$; else if $B_u^{(j)}$ is \filled~then $\ADJ[v][u] = \ZERO$; else $\ADJ[v][u] = \PHI$.
Note that $P_v^{(i)}$'s, maintained by our implementation, are initially empty but may not still be empty at the beginning of the \func{Fill} function call. These $P_v^{(i)}$'s are again instantiated and stored in a dictionary once they become non-empty.
Further, observe that the coin-flips are simulated independently of the state of $P_v^{(i)}$, so the number of iterations of Algorithm~\ref{alg:fill} is the same as the number of coins $C_{vu} = \ONE$ which is, in expectation, a constant (namely $\sum_{u\in B^{(i)}_v} \mathbb P[C_{vu}=\ONE] = \sum_{u\in B^{(i)}_v} p_{vu} \leq L+1$). % at most $M = O(\log n)$ with high probability (over the entire process of filling all $O(n^2)$ blocks throughout the iteration of the generator).
%Identifying $B_u^{(j)}$ containing $v$ requires a binary search, adding $O(\log n)$ time per iteration.



By tracking the resource required by Algorithm~\ref{alg:fill} we obtain the following lemma; note that ``additional space'' refers to the enduring memory that the implementation must allocate and keep even after the execution, not its computation memory. The $\log n$ factors in our complexities are required to perform binary-search for the range of $B^{(i)}_v$, or for the value $u$ from the CDF of $\mathsf{F}(u,a,b)$, and to maintain the ordered sets $P_v^{(i)}$ and $P_u^{(j)}$.

\begin{restatable}{lemma}{fill_time}
\label{lem:fill_time}
Each execution of Algorithm~\ref{alg:fill} (the \func{Fill} operation) on an \unfilled~block $B^{(i)}_v$, in expectation:
\begin{itemize}
\item terminates within $\bo(1)$ iterations (of its \textup{\textbf{repeat}} loop);
\item computes $\bo(\log n)$ quantities of $\prod_{u \in [a,b]} (1-p_{vu})$ and $\sum_{u\in[a,b]} p_{vu}$ each;
\item aside from the above computations, uses $\bo(\log n)$ time, $\bo(1)$ random $N$-bit words, and $\bo(1)$ additional space.
\end{itemize}
\end{restatable}

Observe that the number of iterations required by Algorithm~\ref{alg:fill} only depends on its random coin-flips and independent of the state of the algorithm.
Combining with Lemma~\ref{lem:rand_gen_fast}, we finally obtain polylogarithimc resource bound for our implementation of $\func{Random-Neighbor}$.

\begin{restatable}{corollary}{random_neighbor_time}
\label{cor:random_neighbor_time}
Each execution of Algorithm~\ref{alg:random} (the \func{Random-Neighbor} query), with high probability,
\begin{itemize}
\item terminates within $\bo(\log^2 n)$ iterations (of its \textup{\textbf{repeat}} loop);
\item computes $\bo(\log^3 n)$ quantities of $\prod_{u \in [a,b]} (1-p_{vu})$ and $\sum_{u\in[a,b]} p_{vu}$ each;
\item aside from the above computations, uses $\bo(\log^3 n)$ time, $\bo(\log^2 n)$ random $N$-bit words, and $\bo(\log^2 n)$ additional space.
\end{itemize}
\end{restatable}

\paragraph*{Extension to other query types}
We finally extend our algorithm to support other query types as follows.
\begin{itemize}
\item \func{Vertex-Pair}(u,v): We simply need to make sure that Lemma~\ref{lem:cond-0-fill} holds, so we first apply \func{Fill}$(u,j)$ on block $B_u^{(j)}$ containing $v$ (if needed), then answer accordingly.
\item \func{Next-Neighbor}(v): We maintain $\LAST$, and keep invoking \func{Fill} until we find a neighbor. Recall that by Lemma~\ref{lem:EmptyBlock}, the probability that a particular block is empty is a small constant. Then with high probability, there exists no $\omega(\log n)$ \emph{consecutive} empty blocks $B^{(i)}_v$'s for any vertex $v$, and thus \func{Next-Neighbor} only invokes up to $\bo(\log n)$ calls to \func{Fill}.
\end{itemize}

We summarize the results so far with through the following theorem.

\begin{restatable}{theorem}{res:grand}
\label{thm:grand}
Given a random graph model defined by the probabilty matrix $\{ p_{uv}\}$ and assuming that we can compute the the quantities
$\prod_{u=a}^b (1-p_{vu})$ and $\sum_{u=a}^b p_{vu}$ in polylogarithmic time,
there exists a local-access implementation for this random graph model that supports \func{Random-Neighbor},
\func{Vertex-Pair} and \func{Next-Neighbor} queries using polylogarithmic running time, additional space, and random words per query.
\end{restatable}

We have also been implicitly assuming perfect-precision arithmetic and we relax this assumption in Section~\ref{sec:remove-perfect}.
In the following Section~\ref{sec:applications}, we show applications of Theorem~\ref{thm:grand} to the $G(n,p)$ model,
and the Stochastic Block model under random community assignment,
by providing formulas and by constructing data structures for computing the quantities specified in Theorem~\ref{thm:grand}.
