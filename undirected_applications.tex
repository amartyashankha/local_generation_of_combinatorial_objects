\section{Applications to Erd\"{o}s-R\'{e}nyi Model and Stochastic Block Model}
\label{sec:applications}
In this section we demonstrate the application of our techniques to
two well known, and widely studied models of randon graphs. That is, as required by Theorem~\ref{thm:grand}, we must provide a method for computing the quantities $\prod_{u=a}^b (1-p_{vu})$ and $\sum_{u=a}^b p_{vu}$ of the desired random graph families in logarithmic time, space and random bits.
Our first implementation focuses on the well known Erd\"{o}s-R\'{e}nyi model -- $G(n,p)$: in this case, $p_{vu} = p$ is uniform and our quantities admit closed-form formulas.
%It is quite simple to calculate the CDF for uniform probabilities.
%{\color{red} Should we still be explicitly mentioning the CDFs? now that we have two ``assumptions'' (product and sum) maybe we should tone this section as actually computing them (rather than just providing CDFs). also did we actually mention sums?}

Next, we focus on the Stochastic Block model with randomly-assigned communities.
\iffalse
{\color{red}In this case, a naive solution would be to simply assign communities to contiguous blocks of indices.
In such a setting, the problem of calculating $\mathsf{F}(v,a,b)$, simply reduces to the $G(n,p)$ case,
with some additional case analysis to check when we are at a community boundary.
However, this setup is unrealistic,
and not particularly useful in the context of the Stochastic Block model.
In fact most algorithms operating on these graphs,
are trying to unveil the underlying community structure.}
{\color{blue} I'd say these motivations should show up in intro or preliminaries (for the full version)}
\fi
Our implementation assigns each vertex to a community in $\{C_1, \ldots, C_r\}$ identically and independently at random, according to some given distribution $\mathsf{R}$ over the communities. We formulate a method of sampling community assignments locally.
This essentially allows us to sample from the \emph{multivariate hypergeometric distribution},
using $\poly(\log n)$ random bits, which may be of independent interest. We remark that, as our first step, we sample for the number of vertices of each community. That is, our construction can alternatively support the community assignment where the number of vertices of each community is given, under the assumption that the \emph{partition} of the vertex set into communities is chosen uniformly at random.

\subsection{Erd\"{o}s-R\'{e}nyi Model}
\label{sec:app_er}
As $p_{vu} = p$ for all edges $\{u,v\}$ in the Erd\"{o}s-R\'{e}nyi $G(n,p)$ model, we have the closed-form formulas $\prod_{u=a}^b (1-p_{vu}) = (1-p)^{b-a+1}$ and $\sum_{u=a}^b p_{vu} = (b-a+1)p$, which can be computed in constant time according to our assumption, yielding the following corollary.
\begin{restatable}{corollary}{res:oblivious:corol}
The final algorithm in Section~\ref{sec:undirected} locally generates a random graph from the Erd\"{o}s-R\'{e}nyi $G(n,p)$ model using $\bo(\log^3 n)$ time, $\bo(\log^2 n)$ random $N$-bit words, and $\bo(\log^2 n)$ additional space per query with high probability.
\end{restatable}

We remark that there exists an alternative approach that picks $F\sim\mathsf{F}(v,a,b)$ directly via a closed-form formula $a+\lceil\frac{\log U}{\log (1-p)}\rceil$ where $U$ is drawn uniformly from $[0,1)$, rather than binary-searching for $U$ in its CDF. Such an approach may save some $\poly(\log n)$ factors in the resources, given the prefect-precision arithmetic assumption. This usage of the $\log$ function requires $\Omega(n)$-bit precision, which is not applicable to our computation model.

While we are able to generate our random graph on-the-fly supporting all three types of queries, our construction still only requires $\bo(m+n)$ space ($N$-bit words) in total at any state; that is, we keep $\bo(n)$ words for $\LAST$, $\bo(1)$ words per neighbor in $P_v$'s, and one marking bit for each bucket (where there can be up to $m+n$ buckets in total). Hence, our memory usage is nearly optimal for the $G(n,p)$ model:

\begin{restatable}{corollary}{res:er-optimal}
\label{thm:er-optimal}
The final algorithm in Section~\ref{sec:undirected} can generate a complete random graph
from the Erd\"{o}s-R\'{e}nyi $G(n,p)$ model using overall
$\tilde{\mathcal{O}}(n+m)$ time, random bits and space, which is $\tilde{\bo}(pn^2)$ in expectation.
This is optimal up to $ \mathcal{O}(\poly(\log n))$ factors.
\end{restatable}

\iffalse
The deterministic version (Section~\ref{sec:ER-det}) does not require the extra overhead resulting from failed iterations.
However, the two level data-structure introduces an extra $\Bo(\log n)$ factor, resulting in the same overall running time.
However, this only requires one $N$-bit random word.
\fi





\subsection{Stochastic Block model}
\label{sec:app_sbm}

For the Stochastic Block model, each vertex is assigned to some community $C_i$, $i \in [r]$.
By partitioning the product by communities, we may rewrite the desired formulas, for $v \in C_i$,
as $\prod_{u=a}^b (1-p_{vu}) = \prod_{j=1}^r (1-p_{ij})^{|[a,b]\cap C_j|}$ and $\sum_{u=a}^b p_{vu}=\sum_{j=1}^r |[a,b]\cap C_j|\cdot p_{ij}$.
Thus, it is sufficient to design a data structure, or a \emph{generator},
that draws a community assignment for the vertex set according to the given distribution $\mathsf{R}$.
This data structure should be able to efficiently count the number of occurrences of vertices of each community in any contiguous range,
namely the value $|[a,b]\cap C_j|$ for each $j \in [r]$.
To this end, we use the following lemma (proven in Section~\ref{sec:multivariate_hypergeometric_sampling}),
yielding an implementation for the Stochastic Block model using $O(r\, \poly(\log n))$ resources per query.

\begin{restatable}{theorem}{res:sbm-data}\label{thm:sbm-data}
There exists a data structure (generator) that samples a community for each vertex independently at random from $\mathsf{R}$
with $\frac{1}{\poly(n)}$ error in the $L_1$-distance, and supports queries that ask for the number of occurrences of vertices of each community
in any contiguous range, using $O(r\,\poly(\log n))$ time, random $N$-bit words and additional space per query.
Further, this data structure may be implemented in such a way that requires no overhead for initialization.
\end{restatable}
\begin{restatable}{corollary}{res:sbm-construct}\label{cor:sbm-construct}
The final algorithm in Section~\ref{sec:undirected} generates a random graph from the Stochastic Block model with randomly-assigned communities
using $O(r\,\poly(\log n))$ time, random $N$-bit words, and additional space per query with high probability.
\end{restatable}

\todo{Update}
We provide the full details of the construction in the following Section~\ref{sec:multivariate_hypergeometric_sampling}.
Our construction extends upon a similar generator in the work of \cite{huge} which only supports $r = 2$.
Our overall data structure is a balanced binary tree, where the root corresponds to the entire range of indices $\{1, \ldots, n\}$,
and the children of each vertex corresponds to each half of the parent's range.
Each node\footnote{For clarity, ``vertex'' is only used in the generated graph,
and ``node'' is only used in the internal data structures of the generator.}
holds the number of vertices of each community in its range.
The tree initially contains only the root, with the number of vertices of each community sampled according to the multinomial distribution
\footnote{See e.g., section 3.4.1 of \cite{knuth}} (for $n$ samples (vertices) from the probability distribution $\mathsf{R}$).
The children are only generated top-down on an as-needed basis according to the given queries.
The technical difficulties arise when generating the children,
where one needs to sample ''half'' of the counts of the parent from the correct marginal distribution.
To this end, we show how to sample such a count as described in the statement below.
Namely, we provide an algorithm for sampling from the \emph{multivariate hypergeometric distribution}.
\todo{Link back to previous section}
